{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afb4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from src.api.controllers.calibration_controller import (\n",
    "    get_calibration_recording_by_uuid,\n",
    "    get_class_by_id,\n",
    "    get_gaze_data_path,\n",
    "    get_recording_path,\n",
    ")\n",
    "from src.api.controllers.gaze_controller import (\n",
    "    get_gaze_point_per_frame,\n",
    ")\n",
    "from src.api.models.gaze import GazePoint\n",
    "from src.config import TOBII_GLASSES_FPS, VIEWED_RADIUS\n",
    "from src.utils import (\n",
    "    cv2_video_fps,\n",
    "    cv2_video_frame_count,\n",
    "    cv2_video_resolution,\n",
    "    draw_annotation_on_frame,\n",
    "    extract_frames_to_dir,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from controlled_experiment.settings import (\n",
    "    CLASS_ID_TO_NAME,\n",
    "    FULLY_LABELED_RECORDINGS,\n",
    "    TRIAL_RECORDING_UUIDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a1cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_video_frames(\n",
    "    frames: list[Path],\n",
    "    gaze_point_per_frame: dict[int, GazePoint],\n",
    "    predictions_df: pd.DataFrame,\n",
    "):\n",
    "    # Iterate over frames and draw the annotations on them if they exist\n",
    "    for frame in tqdm(frames, desc=\"Drawing annotations on frames\"):\n",
    "        frame_idx = int(frame.stem)\n",
    "        frame_img = cv2.imread(str(frame))\n",
    "\n",
    "        # iterate through the predictions with the same frame index\n",
    "        frame_predictions = predictions_df[predictions_df[\"frame_idx\"] == frame_idx]\n",
    "        for _, row in frame_predictions.iterrows():\n",
    "            class_id = int(row[\"predicted_class_id\"])\n",
    "            class_name = CLASS_ID_TO_NAME[class_id]\n",
    "            box = (int(row[\"x1\"]), int(row[\"y1\"]), int(row[\"x2\"]), int(row[\"y2\"]))\n",
    "\n",
    "            try:\n",
    "                sim_room_class = get_class_by_id(class_id)\n",
    "                class_color_hex = sim_room_class.color\n",
    "            except ValueError:\n",
    "                # For unknown classes, use a default color\n",
    "                class_color_hex = \"#FF0000\"\n",
    "\n",
    "            frame_img = draw_annotation_on_frame(\n",
    "                frame_img=frame_img,\n",
    "                mask=None,\n",
    "                box=box,\n",
    "                class_color_hex=class_color_hex,\n",
    "                class_name=class_name,\n",
    "            )\n",
    "\n",
    "        # Draw the gaze point on the frame\n",
    "        gaze_point = gaze_point_per_frame.get(frame_idx)\n",
    "        if gaze_point is not None:\n",
    "            gaze_x, gaze_y = gaze_point.position\n",
    "            cv2.circle(\n",
    "                frame_img,\n",
    "                (int(gaze_x), int(gaze_y)),\n",
    "                radius=VIEWED_RADIUS,\n",
    "                color=(0, 0, 255),\n",
    "                thickness=2,\n",
    "            )\n",
    "\n",
    "        # Save the modified image back to its original location\n",
    "        cv2.imwrite(str(frame), frame_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70736275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gaze data for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Loading prediction results for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Extracting frames for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Drawing annotations for 67b71a70-da64-467a-9fb6-91bc29265fd1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drawing annotations on frames: 100%|██████████| 2064/2064 [00:15<00:00, 131.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating video for 67b71a70-da64-467a-9fb6-91bc29265fd1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:   7%|▋         | 1/14 [00:58<12:34, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gaze data for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Loading prediction results for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Extracting frames for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Drawing annotations for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drawing annotations on frames: 100%|██████████| 1365/1365 [00:12<00:00, 105.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating video for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  14%|█▍        | 2/14 [01:38<09:35, 47.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gaze data for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Loading prediction results for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Extracting frames for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Drawing annotations for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drawing annotations on frames: 100%|██████████| 1557/1557 [00:11<00:00, 136.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating video for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings: 100%|██████████| 14/14 [02:19<00:00,  9.93s/it]\n"
     ]
    }
   ],
   "source": [
    "FINAL_PREDICTIONS_PATH = Path(\"data/final_predictions\")\n",
    "RECORDING_FRAMES_PATH = Path(\"data/recording_frames\")\n",
    "\n",
    "FINAL_PREDICTION_VIDEOS_PATH = Path(\"data/final_prediction_videos\")\n",
    "if FINAL_PREDICTION_VIDEOS_PATH.exists():\n",
    "    shutil.rmtree(FINAL_PREDICTION_VIDEOS_PATH)\n",
    "FINAL_PREDICTION_VIDEOS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for trial_recording_uuid in tqdm(\n",
    "    TRIAL_RECORDING_UUIDS, desc=\"Processing trial recordings\"\n",
    "):\n",
    "    if trial_recording_uuid not in FULLY_LABELED_RECORDINGS:\n",
    "        continue\n",
    "\n",
    "    calibration_recording = get_calibration_recording_by_uuid(trial_recording_uuid)\n",
    "\n",
    "    # Get statistics of the video\n",
    "    trial_recording_path = get_recording_path(calibration_recording.id)\n",
    "    trial_video_resolution = cv2_video_resolution(trial_recording_path)\n",
    "    trial_video_fps = cv2_video_fps(trial_recording_path)\n",
    "    trial_video_frame_count = cv2_video_frame_count(trial_recording_path)\n",
    "\n",
    "    # Load and preprocess gaze points\n",
    "    print(f\"Loading gaze data for {trial_recording_uuid}\")\n",
    "    gaze_data_path = get_gaze_data_path(calibration_recording.id)\n",
    "    gaze_point_per_frame = get_gaze_point_per_frame(\n",
    "        gaze_data_path=gaze_data_path,\n",
    "        resolution=trial_video_resolution,\n",
    "        frame_count=trial_video_frame_count,\n",
    "        fps=trial_video_fps,\n",
    "    )\n",
    "\n",
    "    calibration_recording = get_calibration_recording_by_uuid(trial_recording_uuid)\n",
    "\n",
    "    print(f\"Loading prediction results for {trial_recording_uuid}\")\n",
    "    final_predictions_path = FINAL_PREDICTIONS_PATH / f\"{trial_recording_uuid}.csv\"\n",
    "    predictions_df = pd.read_csv(final_predictions_path)\n",
    "\n",
    "    print(f\"Extracting frames for {trial_recording_uuid}\")\n",
    "    tmp_frames_dir = tempfile.TemporaryDirectory()\n",
    "    tmp_frames_path = Path(tmp_frames_dir.name)\n",
    "    extract_frames_to_dir(\n",
    "        video_path=trial_recording_path,\n",
    "        frames_path=tmp_frames_path,\n",
    "        print_output=False,\n",
    "    )\n",
    "    frames = sorted(list(tmp_frames_path.glob(\"*.jpg\")), key=lambda x: int(x.stem))\n",
    "\n",
    "    print(f\"Drawing annotations for {trial_recording_uuid}\")\n",
    "    draw_video_frames(\n",
    "        frames=frames,\n",
    "        gaze_point_per_frame=gaze_point_per_frame,\n",
    "        predictions_df=predictions_df,\n",
    "    )\n",
    "\n",
    "    print(f\"Creating video for {trial_recording_uuid}\")\n",
    "    cmd = f'ffmpeg -hwaccel cuda -y -pattern_type glob -framerate {TOBII_GLASSES_FPS} -i \"{tmp_frames_path!s}/*.jpg\" -c:v libx264 -pix_fmt yuv420p \"{FINAL_PREDICTION_VIDEOS_PATH}/{trial_recording_uuid}.mp4\"'\n",
    "    subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}