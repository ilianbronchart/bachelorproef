{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CHECKPOINTS_PATH\"] = \"../checkpoints\"\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from sqlalchemy.orm import Session\n",
    "from src.api.db import engine\n",
    "from src.api.models.db import Recording\n",
    "from src.api.services import gaze_service\n",
    "from src.config import CHECKPOINTS_PATH, GAZE_FOV, TOBII_FOV_X, TOBII_GLASSES_FPS, TOBII_GLASSES_RESOLUTION\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from tqdm import tqdm\n",
    "from ultralytics import FastSAM\n",
    "from src.api.services import simrooms_service\n",
    "\n",
    "from experiment.settings import (\n",
    "    FULLY_LABELED_RECORDINGS,\n",
    "    GAZE_SEGMENTATION_RESULTS_PATH,\n",
    ")\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n",
    "    trial_recordings = (\n",
    "        session.query(Recording).filter(Recording.id.in_(FULLY_LABELED_RECORDINGS)).all()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting and Tracking based on Gaze Data, and grounding based on previously built Vector Index\n",
    "\n",
    "There's a few considerations that might be interesting in an experimental context:\n",
    "1. Selection of `k` in top-k results from the database?\n",
    "2. Segmentation quality (IOU?, Confidence?)\n",
    "3. Adding padding to the bounding boxes?\n",
    "4. Indexing, search parameters? (which ones exist)\n",
    "5. Merging of same-frame ROIs or not?\n",
    "6. Importance of metrics (average, min, max, variance, ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazeSegmentationJob:\n",
    "    def __init__(\n",
    "        self,\n",
    "        recording_id: int,\n",
    "        results_path: Path,\n",
    "        fovea_fov: float = GAZE_FOV,\n",
    "        fov_x: float = TOBII_FOV_X,\n",
    "        checkpoint_path: str = \"checkpoints/FastSAM-x.pt\",\n",
    "        frames_path: Path | None = None,\n",
    "    ):\n",
    "        self.fovea_fov = fovea_fov\n",
    "        self.fov_x = fov_x\n",
    "\n",
    "        # Set up the results directory.\n",
    "        self.results_path = results_path\n",
    "        if self.results_path.exists():\n",
    "            shutil.rmtree(self.results_path, ignore_errors=True)\n",
    "            self.results_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Extract frames to a temporary directory.\n",
    "        if frames_path is None:\n",
    "            frames, tmp_frames_dir = simrooms_service.extract_tmp_frames(recording_id)\n",
    "            self.tmp_frames_dir = tmp_frames_dir # save this so the temp dir doesn't get garbage collected\n",
    "            self.frames_path = Path(tmp_frames_dir.name)\n",
    "        else:\n",
    "            self.frames_path = frames_path\n",
    "            frames = list(self.frames_path.iterdir())\n",
    "            if not self.frames_path.exists():\n",
    "                raise FileNotFoundError(f\"Frames path {self.frames_path} does not exist.\")\n",
    "\n",
    "        # Load the FastSAM model.\n",
    "        self.model = FastSAM(checkpoint_path)\n",
    "\n",
    "        # Video properties.\n",
    "        self.resolution = TOBII_GLASSES_RESOLUTION\n",
    "        self.aspect_ratio = self.resolution[1] / self.resolution[0]  # W / H\n",
    "        self.fps = TOBII_GLASSES_FPS\n",
    "        self.viewed_radius = int((self.fovea_fov / self.fov_x) * self.resolution[1])\n",
    "        self.frame_count = len(frames)\n",
    "\n",
    "        # Map frame indexes to gaze points.\n",
    "        self.frame_to_gaze_position = gaze_service.get_gaze_position_per_frame(\n",
    "            recording_id=recording_id,\n",
    "            frame_count=self.frame_count,\n",
    "            resolution=self.resolution,\n",
    "            fps=self.fps,\n",
    "        )\n",
    "\n",
    "    def mask_too_large(self, mask: torch.Tensor) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the mask area is less than or equal to 30% of the frame area.\n",
    "\n",
    "        Args:\n",
    "            mask: A tensor containing a single mask of shape (H, W)\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the mask's area is less than or equal to 30% of the frame area, False otherwise.\n",
    "        \"\"\"\n",
    "        MAX_MASK_AREA = 0.1\n",
    "        height, width = mask.shape\n",
    "        frame_area = height * width\n",
    "        max_mask_area = MAX_MASK_AREA * frame_area\n",
    "\n",
    "        mask_area = mask.sum()\n",
    "        return mask_area >= max_mask_area\n",
    "\n",
    "    def run(self):\n",
    "        frame_paths = list(self.frames_path.iterdir())\n",
    "        frame_paths.sort(key=lambda x: int(x.stem))\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for frame_path in frame_paths:\n",
    "                frame_idx = int(frame_path.stem)\n",
    "                results = self.model.track(\n",
    "                    source=str(frame_path), imgsz=640, verbose=False, persist=True\n",
    "                )[0]\n",
    "\n",
    "                try:\n",
    "                    gaze_position = self.frame_to_gaze_position.get(frame_idx)\n",
    "                    if gaze_position is None:\n",
    "                        continue\n",
    "\n",
    "                    boxes = []\n",
    "                    rois = []\n",
    "                    masks = []\n",
    "                    object_ids = []\n",
    "                    confidences = []\n",
    "                    for i in range(len(results.boxes)):\n",
    "                        mask = F.resize(\n",
    "                            results.masks[i].data,\n",
    "                            self.resolution,\n",
    "                            interpolation=InterpolationMode.NEAREST,\n",
    "                        ).squeeze()\n",
    "\n",
    "                        if not self.mask_too_large(mask) and gaze_service.mask_was_viewed(\n",
    "                            mask, gaze_position\n",
    "                        ):\n",
    "                            box = masks_to_boxes(mask.unsqueeze(0)).int().cpu().numpy()[0]\n",
    "                            x1, y1, x2, y2 = box\n",
    "                            roi = results.orig_img[y1:y2, x1:x2, :]\n",
    "                            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                            boxes.append(box)\n",
    "                            masks.append(mask.cpu().numpy().astype(np.uint8))\n",
    "                            rois.append(roi)\n",
    "                            object_ids.append(int(results.boxes.id[i]))\n",
    "                            confidences.append(float(results.boxes[i].conf))\n",
    "\n",
    "\n",
    "                    if len(boxes) > 0:\n",
    "                        rois_array = np.empty(len(rois), dtype=object)\n",
    "                        for i, roi in enumerate(rois):\n",
    "                            rois_array[i] = roi\n",
    "\n",
    "                        masks_array = np.empty(len(masks), dtype=object)\n",
    "                        for i, mask in enumerate(masks):\n",
    "                            masks_array[i] = mask\n",
    "\n",
    "                        # Offload saving with thread pool (asynchronously)\n",
    "                        executor.submit(\n",
    "                            np.savez_compressed,\n",
    "                            self.results_path / f\"{frame_idx}.npz\",\n",
    "                            boxes=boxes,\n",
    "                            rois=rois_array,\n",
    "                            masks=masks_array,\n",
    "                            object_ids=object_ids,\n",
    "                            frame_idx=frame_idx,\n",
    "                            gaze_position=gaze_position,\n",
    "                            confidences=confidences,\n",
    "                        )\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing frame {frame_idx}: {e}\")\n",
    "                    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:  67%|██████▋   | 2/3 [06:09<03:05, 185.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings: 100%|██████████| 3/3 [07:56<00:00, 158.97s/it]\n",
      "Processing recordings: 100%|██████████| 3/3 [07:56<00:00, 158.97s/it]\n"
     ]
    }
   ],
   "source": [
    "if GAZE_SEGMENTATION_RESULTS_PATH.exists():\n",
    "    shutil.rmtree(GAZE_SEGMENTATION_RESULTS_PATH, ignore_errors=True)\n",
    "GAZE_SEGMENTATION_RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FRAMES_PATHS = Path(\"data/recording_frames\")\n",
    "\n",
    "\n",
    "def process_recording(recording: Recording):\n",
    "    \"\"\"\n",
    "    Process a recording for gaze segmentation.\n",
    "    \"\"\"\n",
    "    recording_id = recording.id\n",
    "    frames_path = FRAMES_PATHS / recording_id\n",
    "    results_path = GAZE_SEGMENTATION_RESULTS_PATH / recording_id\n",
    "\n",
    "    if results_path.exists():\n",
    "        shutil.rmtree(results_path, ignore_errors=True)\n",
    "    results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    job = GazeSegmentationJob(\n",
    "        recording_id=recording_id,\n",
    "        results_path=results_path,\n",
    "        fovea_fov=GAZE_FOV,\n",
    "        fov_x=TOBII_FOV_X,\n",
    "        checkpoint_path=CHECKPOINTS_PATH / \"FastSAM-x.pt\",\n",
    "        frames_path=frames_path,\n",
    "    )\n",
    "    job.run()\n",
    "\n",
    "\n",
    "for recording in tqdm(trial_recordings, desc=\"Processing recordings\"):\n",
    "    if recording.id in FULLY_LABELED_RECORDINGS:\n",
    "        process_recording(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.api.utils import image_utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tempfile\n",
    "# from src.utils import extract_frames_to_dir\n",
    "\n",
    "# RECORDING_ID = \"32f02db7-adc0-4556-a2da-ed2ba60a58c9\"\n",
    "# SEG_RESULTS_PATH = GAZE_SEGMENTATION_RESULTS_PATH / RECORDING_ID\n",
    "# VIDEO_PATH = Path(\"data/recordings\") / f\"{RECORDING_ID}.mp4\"\n",
    "\n",
    "# temp_video_frames_path = Path(tempfile.gettempdir()) / f\"{RECORDING_ID}\"\n",
    "# if temp_video_frames_path.exists():\n",
    "#     shutil.rmtree(temp_video_frames_path, ignore_errors=True)\n",
    "# temp_video_frames_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# extract_frames_to_dir(\n",
    "#     video_path=VIDEO_PATH,\n",
    "#     frames_path=temp_video_frames_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = list(temp_video_frames_path.iterdir())\n",
    "# seg_results = list(SEG_RESULTS_PATH.iterdir())\n",
    "# seg_results.sort(key=lambda x: int(x.stem))\n",
    "\n",
    "# frame_id_to_path = {int(frame.stem): frame for frame in frames}\n",
    "\n",
    "# for i, results in enumerate(tqdm(seg_results)):\n",
    "#     frame_idx = int(results.stem)\n",
    "#     frame_path = frame_id_to_path[frame_idx]\n",
    "\n",
    "#     frame = cv2.imread(str(frame_path))\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     results_file = np.load(results, allow_pickle=True)\n",
    "\n",
    "#     boxes = results_file[\"boxes\"]\n",
    "#     masks = results_file[\"masks\"]\n",
    "#     object_ids = results_file[\"object_ids\"]\n",
    "\n",
    "#     combined_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "#     for mask in masks:\n",
    "#         combined_mask = np.logical_or(combined_mask, mask)\n",
    "\n",
    "#     image_utils.draw_mask(\n",
    "#         img=frame,\n",
    "#         mask=combined_mask,\n",
    "#         box=(0, 0, frame.shape[1], frame.shape[0]),\n",
    "#     )\n",
    "\n",
    "#     for j in range(len(boxes)):\n",
    "#         image_utils.draw_labeled_box(\n",
    "#             img=frame, box=tuple(boxes[j]), label=f\"ID: {object_ids[j]}\", color=\"#FF0000\"\n",
    "#         )\n",
    "\n",
    "#     # save back to original path\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     cv2.imwrite(str(frame_path), frame)\n",
    "\n",
    "# import subprocess\n",
    "\n",
    "# cmd = f'ffmpeg -hwaccel cuda -y -pattern_type glob -framerate {TOBII_GLASSES_FPS} -i \"{temp_video_frames_path!s}/*.jpg\" -c:v libx264 -pix_fmt yuv420p \"test.mp4\"'\n",
    "# subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorproef-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
