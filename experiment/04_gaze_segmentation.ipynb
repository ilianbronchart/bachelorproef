{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CHECKPOINTS_PATH\"] = \"../checkpoints\"\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from sqlalchemy.orm import Session\n",
    "from src.api.db import engine\n",
    "from src.api.models.db import Recording\n",
    "from src.api.services import gaze_service\n",
    "from src.config import CHECKPOINTS_PATH, GAZE_FOV, TOBII_FOV_X, TOBII_GLASSES_FPS, TOBII_GLASSES_RESOLUTION\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from tqdm import tqdm\n",
    "from ultralytics import FastSAM\n",
    "from src.api.services import simrooms_service\n",
    "\n",
    "from experiment.settings import (\n",
    "    FULLY_LABELED_RECORDINGS,\n",
    "    GAZE_SEGMENTATION_RESULTS_PATH,\n",
    ")\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n",
    "    trial_recordings = (\n",
    "        session.query(Recording).filter(Recording.id.in_(FULLY_LABELED_RECORDINGS)).all()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting and Tracking based on Gaze Data, and grounding based on previously built Vector Index\n",
    "\n",
    "There's a few considerations that might be interesting in an experimental context:\n",
    "1. Selection of `k` in top-k results from the database?\n",
    "2. Segmentation quality (IOU?, Confidence?)\n",
    "3. Adding padding to the bounding boxes?\n",
    "4. Indexing, search parameters? (which ones exist)\n",
    "5. Merging of same-frame ROIs or not?\n",
    "6. Importance of metrics (average, min, max, variance, ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazeSegmentationJob:\n",
    "    def __init__(\n",
    "        self,\n",
    "        recording_id: int,\n",
    "        results_path: Path,\n",
    "        fovea_fov: float = GAZE_FOV,\n",
    "        fov_x: float = TOBII_FOV_X,\n",
    "        checkpoint_path: str = \"checkpoints/FastSAM-x.pt\",\n",
    "        frames_path: Path | None = None,\n",
    "        filter_by_gaze: bool = True\n",
    "    ):\n",
    "        self.fovea_fov = fovea_fov\n",
    "        self.fov_x = fov_x\n",
    "        self.filter_by_gaze = filter_by_gaze\n",
    "\n",
    "        # Set up the results directory.\n",
    "        self.results_path = results_path\n",
    "        if self.results_path.exists():\n",
    "            shutil.rmtree(self.results_path, ignore_errors=True)\n",
    "            self.results_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Extract frames to a temporary directory.\n",
    "        if frames_path is None:\n",
    "            frames, tmp_frames_dir = simrooms_service.extract_tmp_frames(recording_id)\n",
    "            self.tmp_frames_dir = tmp_frames_dir # save this so the temp dir doesn't get garbage collected\n",
    "            self.frames_path = Path(tmp_frames_dir.name)\n",
    "        else:\n",
    "            self.frames_path = frames_path\n",
    "            frames = list(self.frames_path.iterdir())\n",
    "            if not self.frames_path.exists():\n",
    "                raise FileNotFoundError(f\"Frames path {self.frames_path} does not exist.\")\n",
    "\n",
    "        # Load the FastSAM model.\n",
    "        self.model = FastSAM(checkpoint_path)\n",
    "\n",
    "        # Video properties.\n",
    "        self.resolution = TOBII_GLASSES_RESOLUTION\n",
    "        self.aspect_ratio = self.resolution[1] / self.resolution[0]  # W / H\n",
    "        self.fps = TOBII_GLASSES_FPS\n",
    "        self.viewed_radius = int((self.fovea_fov / self.fov_x) * self.resolution[1])\n",
    "        self.frame_count = len(frames)\n",
    "\n",
    "        # Map frame indexes to gaze points.\n",
    "        self.frame_to_gaze_position = gaze_service.get_gaze_position_per_frame(\n",
    "            recording_id=recording_id,\n",
    "            frame_count=self.frame_count,\n",
    "            resolution=self.resolution,\n",
    "            fps=self.fps,\n",
    "        )\n",
    "\n",
    "    def mask_too_large(self, mask: torch.Tensor) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the mask area is less than or equal to 30% of the frame area.\n",
    "\n",
    "        Args:\n",
    "            mask: A tensor containing a single mask of shape (H, W)\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the mask's area is less than or equal to 30% of the frame area, False otherwise.\n",
    "        \"\"\"\n",
    "        MAX_MASK_AREA = 0.1\n",
    "        height, width = mask.shape\n",
    "        frame_area = height * width\n",
    "        max_mask_area = MAX_MASK_AREA * frame_area\n",
    "\n",
    "        mask_area = mask.sum()\n",
    "        return mask_area >= max_mask_area\n",
    "\n",
    "    def run(self):\n",
    "        frame_paths = list(self.frames_path.iterdir())\n",
    "        frame_paths.sort(key=lambda x: int(x.stem))\n",
    "\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for frame_path in frame_paths:\n",
    "                frame_idx = int(frame_path.stem)\n",
    "                results = self.model.track(\n",
    "                    source=str(frame_path), imgsz=640, verbose=False, persist=True\n",
    "                )[0]\n",
    "\n",
    "                try:\n",
    "                    gaze_position = self.frame_to_gaze_position.get(frame_idx)\n",
    "                    if gaze_position is None:\n",
    "                        continue\n",
    "\n",
    "                    boxes = []\n",
    "                    rois = []\n",
    "                    masks = []\n",
    "                    object_ids = []\n",
    "                    confidences = []\n",
    "                    for i in range(len(results.boxes)):\n",
    "                        mask = F.resize(\n",
    "                            results.masks[i].data,\n",
    "                            self.resolution,\n",
    "                            interpolation=InterpolationMode.NEAREST,\n",
    "                        ).squeeze()\n",
    "\n",
    "                        if not self.mask_too_large(mask) and (gaze_service.mask_was_viewed(mask, gaze_position) or not self.filter_by_gaze) and mask.any():\n",
    "                            box = masks_to_boxes(mask.unsqueeze(0)).int().cpu().numpy()[0]\n",
    "                            x1, y1, x2, y2 = box\n",
    "                            roi = results.orig_img[y1:y2, x1:x2, :]\n",
    "                            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                            boxes.append(box)\n",
    "                            masks.append(mask.cpu().numpy().astype(np.uint8))\n",
    "                            rois.append(roi)\n",
    "                            object_ids.append(int(results.boxes.id[i]))\n",
    "                            confidences.append(float(results.boxes[i].conf))\n",
    "\n",
    "\n",
    "                    if len(boxes) > 0:\n",
    "                        rois_array = np.empty(len(rois), dtype=object)\n",
    "                        for i, roi in enumerate(rois):\n",
    "                            rois_array[i] = roi\n",
    "\n",
    "                        masks_array = np.empty(len(masks), dtype=object)\n",
    "                        for i, mask in enumerate(masks):\n",
    "                            masks_array[i] = mask\n",
    "\n",
    "                        # Offload saving with thread pool (asynchronously)\n",
    "                        executor.submit(\n",
    "                            np.savez_compressed,\n",
    "                            self.results_path / f\"{frame_idx}.npz\",\n",
    "                            boxes=boxes,\n",
    "                            rois=rois_array,\n",
    "                            masks=masks_array,\n",
    "                            object_ids=object_ids,\n",
    "                            frame_idx=frame_idx,\n",
    "                            gaze_position=gaze_position,\n",
    "                            confidences=confidences,\n",
    "                        )\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing frame {frame_idx}: {e}\")\n",
    "                    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:  10%|█         | 1/10 [02:15<20:22, 135.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:  20%|██        | 2/10 [03:43<14:20, 107.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:  70%|███████   | 7/10 [11:15<04:21, 87.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings:  90%|█████████ | 9/10 [14:19<01:28, 88.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Detected 3 gaze points for a frame in the video. This is unexpected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recordings: 100%|██████████| 10/10 [15:51<00:00, 95.19s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "FILTER_RESULTS = True\n",
    "\n",
    "if FILTER_RESULTS:\n",
    "    if GAZE_SEGMENTATION_RESULTS_PATH.exists():\n",
    "        shutil.rmtree(GAZE_SEGMENTATION_RESULTS_PATH, ignore_errors=True)\n",
    "    GAZE_SEGMENTATION_RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    UNFILTERED_GAZE_SEGMENTATION_RESULTS_PATH = Path(\"data/unfiltered_gaze_segmentation_results\")\n",
    "    if UNFILTERED_GAZE_SEGMENTATION_RESULTS_PATH.exists():\n",
    "        shutil.rmtree(UNFILTERED_GAZE_SEGMENTATION_RESULTS_PATH, ignore_errors=True)\n",
    "    UNFILTERED_GAZE_SEGMENTATION_RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FRAMES_PATHS = Path(\"data/recording_frames\")\n",
    "\n",
    "def process_recording(recording: Recording):\n",
    "    \"\"\"\n",
    "    Process a recording for gaze segmentation.\n",
    "    \"\"\"\n",
    "    recording_id = recording.id\n",
    "    frames_path = FRAMES_PATHS / recording_id\n",
    "\n",
    "    if FILTER_RESULTS:\n",
    "        results_path = GAZE_SEGMENTATION_RESULTS_PATH / recording_id\n",
    "    else:\n",
    "        results_path = UNFILTERED_GAZE_SEGMENTATION_RESULTS_PATH / recording_id\n",
    "\n",
    "    if results_path.exists():\n",
    "        shutil.rmtree(results_path, ignore_errors=True)\n",
    "    results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    job = GazeSegmentationJob(\n",
    "        recording_id=recording_id,\n",
    "        results_path=results_path,\n",
    "        fovea_fov=GAZE_FOV,\n",
    "        fov_x=TOBII_FOV_X,\n",
    "        checkpoint_path=CHECKPOINTS_PATH / \"FastSAM-x.pt\",\n",
    "        frames_path=frames_path,\n",
    "        filter_by_gaze=FILTER_RESULTS,\n",
    "    )\n",
    "    job.run()\n",
    "\n",
    "for recording in tqdm(trial_recordings, desc=\"Processing recordings\"):\n",
    "    if recording.id in FULLY_LABELED_RECORDINGS:\n",
    "        process_recording(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendering the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.api.utils import image_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from src.utils import extract_frames_to_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1878/1878 [08:31<00:00,  3.67it/s]\n",
      "100%|██████████| 1309/1309 [05:16<00:00,  4.14it/s]\n",
      " 58%|█████▊    | 872/1498 [04:21<03:07,  3.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m results_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(results, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m boxes \u001b[38;5;241m=\u001b[39m results_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43mresults_file\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmasks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     32\u001b[0m object_ids \u001b[38;5;241m=\u001b[39m results_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     34\u001b[0m combined_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[0;32m~/projects/bachelorproef/.venv/lib/python3.10/site-packages/numpy/lib/npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/projects/bachelorproef/.venv/lib/python3.10/site-packages/numpy/lib/format.py:800\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    798\u001b[0m     pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 800\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# Friendlier error message\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnpickling a python object failed: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    804\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may need to pass the encoding= option \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    805\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto numpy.load\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (err,)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/zipfile.py:930\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 930\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m/usr/lib/python3.10/zipfile.py:1006\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m   1005\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1006\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for recording_id in FULLY_LABELED_RECORDINGS:\n",
    "    SEG_RESULTS_PATH = UNFILTERED_GAZE_SEGMENTATION_RESULTS_PATH / recording_id\n",
    "    VIDEO_PATH = Path(\"data/recordings\") / f\"{recording_id}.mp4\"\n",
    "\n",
    "    temp_video_frames_path = Path(tempfile.gettempdir()) / f\"{recording_id}\"\n",
    "    if temp_video_frames_path.exists():\n",
    "        shutil.rmtree(temp_video_frames_path, ignore_errors=True)\n",
    "    temp_video_frames_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    extract_frames_to_dir(\n",
    "        video_path=VIDEO_PATH,\n",
    "        frames_path=temp_video_frames_path,\n",
    "    )\n",
    "\n",
    "    frames = list(temp_video_frames_path.iterdir())\n",
    "    seg_results = list(SEG_RESULTS_PATH.iterdir())\n",
    "    seg_results.sort(key=lambda x: int(x.stem))\n",
    "\n",
    "    frame_id_to_path = {int(frame.stem): frame for frame in frames}\n",
    "\n",
    "    for i, results in enumerate(tqdm(seg_results)):\n",
    "        frame_idx = int(results.stem)\n",
    "        frame_path = frame_id_to_path[frame_idx]\n",
    "\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results_file = np.load(results, allow_pickle=True)\n",
    "\n",
    "        boxes = results_file[\"boxes\"]\n",
    "        masks = results_file[\"masks\"]\n",
    "        object_ids = results_file[\"object_ids\"]\n",
    "\n",
    "        combined_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
    "        for mask in masks:\n",
    "            combined_mask = np.logical_or(combined_mask, mask)\n",
    "\n",
    "        image_utils.draw_mask(\n",
    "            img=frame,\n",
    "            mask=combined_mask,\n",
    "            box=(0, 0, frame.shape[1], frame.shape[0]),\n",
    "        )\n",
    "\n",
    "        for j in range(len(boxes)):\n",
    "            image_utils.draw_labeled_box(\n",
    "                img=frame, box=tuple(boxes[j]), label=f\"ID: {object_ids[j]}\", color=\"#FF0000\"\n",
    "            )\n",
    "\n",
    "        # save back to original path\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imwrite(str(frame_path), frame)\n",
    "\n",
    "    import subprocess\n",
    "\n",
    "    cmd = f'ffmpeg -hwaccel cuda -y -pattern_type glob -framerate {TOBII_GLASSES_FPS} -i \"{temp_video_frames_path!s}/*.jpg\" -c:v libx264 -pix_fmt yuv420p \"test.mp4\"'\n",
    "    subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorproef-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
