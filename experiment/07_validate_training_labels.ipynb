{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CHECKPOINTS_PATH\"] = \"../checkpoints\"\n",
    "os.environ[\"TRACKING_RESULTS_PATH\"] = \"data/processed_tracking_results\"\n",
    "\n",
    "import itertools\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.api.models.pydantic import SimRoomClassDTO\n",
    "from src.config import UNKNOWN_CLASS_ID\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from experiment.prediction_utils import (\n",
    "    calculate_metrics,\n",
    "    create_confusion_matrix,\n",
    "    evaluate_predictions,\n",
    "    render_confusion_matrix,\n",
    "    update_confusion_matrix,\n",
    ")\n",
    "from experiment.settings import (\n",
    "    CLASS_ID_TO_NAME,\n",
    "    FINAL_PREDICTIONS_PATH,\n",
    "    FULLY_LABELED_RECORDINGS,\n",
    "    GAZE_SEGMENTATION_RESULTS_PATH,\n",
    "    LABELING_REC_DIFF_BACKGROUND_ID,\n",
    "    LABELING_REC_SAME_BACKGROUND_ID,\n",
    "    OBJECT_DATASETS_PATH,\n",
    "    TRAINING_DATASETS_PATH,\n",
    "    YOLO_MODELS_PATH,\n",
    "    RECORDING_FRAMES_PATH,\n",
    "    SIMROOM_ID,\n",
    "    LABELING_VALIDATION_VIDEOS_PATH,\n",
    "    RECORDINGS_PATH,\n",
    "    PROCESSED_TRACKING_RESULTS_PATH,\n",
    ")\n",
    "from src.api.db import Session, engine\n",
    "from src.api.repositories import simrooms_repo\n",
    "from src.api.services import simrooms_service\n",
    "import cv2\n",
    "import numpy as np\n",
    "from src.config import TOBII_GLASSES_FPS\n",
    "import torch\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracking_results_per_class(session: Session, labeling_recording_id: str):\n",
    "    calibration_id = simrooms_repo.get_calibration_recording(\n",
    "        session, simroom_id=SIMROOM_ID, recording_id=labeling_recording_id\n",
    "    ).id\n",
    "    tracked_classes = simrooms_repo.get_tracked_classes(session, calibration_id)\n",
    "\n",
    "    if len(tracked_classes) != 15:\n",
    "        raise ValueError(f\"Expected 15 tracked classes but got {len(tracked_classes)}\")\n",
    "\n",
    "    tracking_results_per_class = {\n",
    "        tracked_class.id: simrooms_repo.get_tracking_result_paths(\n",
    "            session, calibration_id, tracked_class.id\n",
    "        )\n",
    "        for tracked_class in tracked_classes\n",
    "    }\n",
    "\n",
    "    return tracking_results_per_class, tracked_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fed97",
   "metadata": {},
   "source": [
    "# Draw graphs of Mask and Bounding Box sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tracking_results(session: Session, labeling_recording_id: str):\n",
    "    tracking_results_per_class, tracked_classes = get_tracking_results_per_class(\n",
    "        session, labeling_recording_id\n",
    "    )\n",
    "\n",
    "    for tracked_class in tracked_classes:\n",
    "        class_id = tracked_class.id\n",
    "        tracking_results = tracking_results_per_class[class_id]\n",
    "        tracking_results = sorted(tracking_results, key=lambda x: int(x.stem))\n",
    "\n",
    "        last_frame_idx = int(tracking_results[-1].stem)\n",
    "        mask_size_per_frame = {frame_idx: None for frame_idx in range(last_frame_idx + 1)}\n",
    "        box_size_per_frame = {frame_idx: None for frame_idx in range(last_frame_idx + 1)}\n",
    "\n",
    "        for tracking_result in tracking_results:\n",
    "            frame_idx = int(tracking_result.stem)\n",
    "            result = np.load(tracking_result)\n",
    "            mask_size = np.sum(result[\"mask\"])\n",
    "            x1, y1, x2, y2 = result[\"box\"]\n",
    "            box_size = (x2 - x1) * (y2 - y1)\n",
    "            mask_size_per_frame[frame_idx] = mask_size\n",
    "            box_size_per_frame[frame_idx] = box_size\n",
    "\n",
    "        plot_frames = []\n",
    "        plot_mask_sizes = []\n",
    "        plot_box_sizes = []\n",
    "\n",
    "        for frame_idx in range(last_frame_idx + 1):\n",
    "            mask_size = mask_size_per_frame[frame_idx]\n",
    "            box_size = box_size_per_frame[frame_idx]\n",
    "            if mask_size is not None:\n",
    "                plot_frames.append(frame_idx)\n",
    "                plot_mask_sizes.append(mask_size)\n",
    "                plot_box_sizes.append(box_size)\n",
    "\n",
    "        if not plot_frames:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(plot_frames, plot_mask_sizes, \"o\", color=tracked_class.color)\n",
    "        plt.xlabel(\"Frame Index\")\n",
    "        plt.ylabel(\"Mask Size\")\n",
    "        plt.title(f\"Mask Size per Frame for Class: {CLASS_ID_TO_NAME[class_id]}\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        plt.plot(plot_frames, plot_box_sizes, \"o\", color=tracked_class.color)\n",
    "        plt.xlabel(\"Frame Index\")\n",
    "        plt.ylabel(\"Box Size\")\n",
    "        plt.title(f\"Box Size per Frame for Class: {CLASS_ID_TO_NAME[class_id]}\")\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07423d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session(engine) as session:\n",
    "    validate_tracking_results(session, LABELING_REC_SAME_BACKGROUND_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a45fde",
   "metadata": {},
   "source": [
    "# Create Validation Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4537fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from src.utils import extract_frames_to_dir\n",
    "from tqdm import tqdm\n",
    "from src.api.utils import image_utils\n",
    "import tempfile\n",
    "from torchvision.ops import masks_to_boxes\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d38049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_validation_video_frames(\n",
    "    frames: list[Path],\n",
    "    annotations_per_frame: dict[int, list[Path]],\n",
    "    tracked_classes: list[SimRoomClassDTO],\n",
    "):\n",
    "    class_id_to_annotated_class = {\n",
    "        anno_class.id: anno_class for anno_class in tracked_classes\n",
    "    }\n",
    "\n",
    "    # Iterate over frames and draw the annotations on them if they exist\n",
    "    for frame in tqdm(frames, desc=\"Drawing annotations on frames\"):\n",
    "        frame_idx = int(frame.stem)\n",
    "        frame_img = cv2.imread(str(frame))\n",
    "\n",
    "        if annotations_per_frame.get(frame_idx) is not None:\n",
    "            for annotation_path in annotations_per_frame[frame_idx]:\n",
    "                annotation_file = np.load(annotation_path)\n",
    "                class_id = int(annotation_file[\"class_id\"])\n",
    "                x1, y1, x2, y2 = annotation_file[\"box\"]\n",
    "                mask = annotation_file[\"mask\"]\n",
    "\n",
    "                # TEST\n",
    "                eroded_mask = cv2.erode(\n",
    "                    mask[0].astype(np.uint8), np.ones((3, 3), np.uint8), iterations=1\n",
    "                )\n",
    "                mask = cv2.dilate(eroded_mask, np.ones((3, 3), np.uint8), iterations=1)\n",
    "                mask_torch = torch.from_numpy(mask).unsqueeze(0)\n",
    "\n",
    "                # create empty 1920x1080 tensor\n",
    "                full_mask = torch.zeros((1, 1080, 1920), dtype=torch.uint8)\n",
    "                full_mask[:, y1:y2, x1:x2] = mask_torch\n",
    "\n",
    "                boxes = masks_to_boxes(full_mask)\n",
    "                x1, y1, x2, y2 = boxes[0].int().tolist()\n",
    "                mask = full_mask[0, y1:y2, x1:x2].numpy()\n",
    "                # TEST\n",
    "\n",
    "                # Squeeze mask if it has an extra dimension\n",
    "                if mask.ndim == 3 and mask.shape[0] == 1:\n",
    "                    mask = mask[0]\n",
    "                if mask.dtype != bool:\n",
    "                    mask = mask.astype(bool)\n",
    "\n",
    "                color = class_id_to_annotated_class[class_id].color\n",
    "                class_name = class_id_to_annotated_class[class_id].class_name\n",
    "                box = (x1, y1, x2, y2)\n",
    "\n",
    "                frame_img = image_utils.draw_mask(frame_img, mask, box)\n",
    "                frame_img = image_utils.draw_labeled_box(\n",
    "                    frame_img, box, class_name, color\n",
    "                )\n",
    "\n",
    "        # Save the modified image back to its original location\n",
    "        cv2.imwrite(str(frame), frame_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae10418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_video(\n",
    "    class_tracking_results: list[Path],\n",
    "    tracked_class: SimRoomClassDTO,\n",
    "    labeling_recording_id: str,\n",
    "    result_videos_path: Path,\n",
    "):\n",
    "    # Extract frames from the video and save them to a temporary directory\n",
    "    print(f\"Extracting frames for {labeling_recording_id}\")\n",
    "    video_path = RECORDINGS_PATH / f\"{labeling_recording_id}.mp4\"\n",
    "    tmp_frames_dir = tempfile.TemporaryDirectory()\n",
    "    tmp_frames_path = Path(tmp_frames_dir.name)\n",
    "    extract_frames_to_dir(\n",
    "        video_path=video_path,\n",
    "        frames_path=tmp_frames_path,\n",
    "        print_output=False,\n",
    "    )\n",
    "    frames = sorted(list(tmp_frames_path.glob(\"*.jpg\")), key=lambda x: int(x.stem))\n",
    "\n",
    "    # Gather annotations for each frame\n",
    "    print(f\"Gathering annotations for {labeling_recording_id}\")\n",
    "    annotations_per_frame: dict[int, list[Path]] = {}\n",
    "    for tracking_result in class_tracking_results:\n",
    "        frame_idx = int(tracking_result.stem)\n",
    "        if frame_idx not in annotations_per_frame:\n",
    "            annotations_per_frame[frame_idx] = []\n",
    "\n",
    "        annotations_per_frame[frame_idx].append(tracking_result)\n",
    "\n",
    "    print(f\"Drawing annotations for {labeling_recording_id}\")\n",
    "    draw_validation_video_frames(\n",
    "        frames=frames,\n",
    "        annotations_per_frame=annotations_per_frame,\n",
    "        tracked_classes=[tracked_class],\n",
    "    )\n",
    "\n",
    "    print(f\"Creating video for {labeling_recording_id}\")\n",
    "    cmd = f'ffmpeg -hwaccel cuda -y -pattern_type glob -framerate {TOBII_GLASSES_FPS} -i \"{str(tmp_frames_path)!s}/*.jpg\" -c:v libx264 -pix_fmt yuv420p \"{result_videos_path}/{CLASS_ID_TO_NAME[tracked_class.id]}.mp4\"'\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "\n",
    "def create_validation_videos(session, labeling_recording_id, selected_class_ids):\n",
    "    result_videos_path = LABELING_VALIDATION_VIDEOS_PATH / labeling_recording_id\n",
    "    result_videos_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    calibration_id = simrooms_repo.get_calibration_recording(\n",
    "        session, simroom_id=SIMROOM_ID, recording_id=labeling_recording_id\n",
    "    ).id\n",
    "    tracked_classes = simrooms_repo.get_tracked_classes(session, calibration_id)\n",
    "\n",
    "    tracking_results_per_class, _ = get_tracking_results_per_class(\n",
    "        session, labeling_recording_id\n",
    "    )\n",
    "\n",
    "    for tracked_class in tracked_classes:\n",
    "        class_id = tracked_class.id\n",
    "        if class_id not in selected_class_ids:\n",
    "            continue\n",
    "\n",
    "        class_tracking_results = tracking_results_per_class[class_id]\n",
    "\n",
    "        create_validation_video(\n",
    "            class_tracking_results=class_tracking_results,\n",
    "            tracked_class=tracked_class,\n",
    "            labeling_recording_id=labeling_recording_id,\n",
    "            result_videos_path=result_videos_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c857e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_class_ids = [10]\n",
    "\n",
    "with Session(engine) as session:\n",
    "    create_validation_videos(session, LABELING_REC_SAME_BACKGROUND_ID, selected_class_ids)\n",
    "    # create_validation_videos(session, LABELING_REC_DIFF_BACKGROUND_ID, selected_class_ids)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
