{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cd7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CHECKPOINTS_PATH\"] = \"../checkpoints\"\n",
    "\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sqlalchemy.orm import Session\n",
    "from src.api.db import engine\n",
    "from src.api.models.gaze import GazePoint\n",
    "from src.api.models.pydantic import SimRoomClassDTO\n",
    "from src.api.repositories import simrooms_repo\n",
    "from src.api.services import gaze_service, simrooms_service, labeling_service\n",
    "from src.config import TOBII_GLASSES_FPS, VIEWED_RADIUS, TOBII_GLASSES_RESOLUTION\n",
    "from src.api.utils import image_utils\n",
    "from src.utils import (\n",
    "    extract_frames_to_dir,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from experiment.settings import (\n",
    "    FULLY_LABELED_RECORDINGS,\n",
    "    GROUND_TRUTH_PATH,\n",
    "    LABELING_VALIDATION_VIDEOS_PATH,\n",
    "    SIMROOM_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0d202",
   "metadata": {},
   "source": [
    "# Create the ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4fb15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mask', 'box', 'roi', 'class_id', 'frame_idx']\n"
     ]
    }
   ],
   "source": [
    "print(np.load(\"data/labeling_results/2/1/0.npz\").files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58422dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viewed_annotations_per_frame(\n",
    "    cal_rec_id: int,\n",
    "    tracked_classes: list[SimRoomClassDTO],\n",
    "    gaze_position_per_frame: dict[int, GazePoint],\n",
    "    video_resolution: tuple[int, int] = TOBII_GLASSES_RESOLUTION,\n",
    "):\n",
    "    # Gather all annotation paths for each annotated frame\n",
    "    annotations_per_frame: dict[int, list[Path]] = {}\n",
    "    for anno_class in tracked_classes:\n",
    "        annotation_paths = labeling_service.get_class_tracking_results(\n",
    "            calibration_id=cal_rec_id, class_id=anno_class.id\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Processing {len(annotation_paths)} annotations for class {anno_class.class_name}\"\n",
    "        )\n",
    "        for annotation_path in tqdm(annotation_paths):\n",
    "            frame_idx = int(annotation_path.stem)\n",
    "\n",
    "            annotation_file = np.load(annotation_path)\n",
    "            mask = annotation_file[\"mask\"]\n",
    "            x1, y1, x2, y2 = annotation_file[\"box\"]\n",
    "\n",
    "            # Put the mask in a tensor of the same size as the video frame\n",
    "            mask_full = np.zeros(video_resolution, dtype=np.uint8)\n",
    "            mask_full[y1:y2, x1:x2] = mask\n",
    "            mask_full_torch = torch.from_numpy(mask_full)\n",
    "\n",
    "            gaze_position = gaze_position_per_frame.get(frame_idx)\n",
    "            if gaze_position is None:\n",
    "                continue\n",
    "\n",
    "            if gaze_service.mask_was_viewed(mask_full_torch, gaze_position):\n",
    "                if frame_idx not in annotations_per_frame:\n",
    "                    annotations_per_frame[frame_idx] = []\n",
    "\n",
    "                annotations_per_frame[frame_idx].append(annotation_path)\n",
    "\n",
    "    return annotations_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acf39ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_validation_video_frames(\n",
    "    frames: list[Path],\n",
    "    annotations_per_frame: dict[int, list[Path]],\n",
    "    gaze_position_per_frame: dict[int, GazePoint],\n",
    "    tracked_classes: list[SimRoomClassDTO],\n",
    "):\n",
    "    class_id_to_annotated_class = {\n",
    "        anno_class.id: anno_class for anno_class in tracked_classes\n",
    "    }\n",
    "\n",
    "    # Iterate over frames and draw the annotations on them if they exist\n",
    "    for frame in tqdm(frames, desc=\"Drawing annotations on frames\"):\n",
    "        frame_idx = int(frame.stem)\n",
    "        frame_img = cv2.imread(str(frame))\n",
    "\n",
    "        if annotations_per_frame.get(frame_idx) is not None:\n",
    "            for annotation_path in annotations_per_frame[frame_idx]:\n",
    "                annotation_file = np.load(annotation_path)\n",
    "                class_id = int(annotation_file[\"class_id\"])\n",
    "                x1, y1, x2, y2 = annotation_file[\"box\"]\n",
    "                mask = annotation_file[\"mask\"]\n",
    "\n",
    "                # Squeeze mask if it has an extra dimension\n",
    "                if mask.ndim == 3 and mask.shape[0] == 1:\n",
    "                    mask = mask[0]\n",
    "                if mask.dtype != bool:\n",
    "                    mask = mask.astype(bool)\n",
    "\n",
    "                color = class_id_to_annotated_class[class_id].color\n",
    "                class_name = class_id_to_annotated_class[class_id].class_name\n",
    "                box = (x1, y1, x2, y2)\n",
    "\n",
    "                frame_img = image_utils.draw_mask(frame_img, mask, box)\n",
    "                frame_img = image_utils.draw_labeled_box(\n",
    "                    frame_img, box, class_name, color\n",
    "                )\n",
    "\n",
    "        # Draw the gaze point on the frame\n",
    "        gaze_position = gaze_position_per_frame.get(frame_idx)\n",
    "        if gaze_position is not None:\n",
    "            gaze_x, gaze_y = gaze_position\n",
    "            cv2.circle(\n",
    "                frame_img,\n",
    "                (int(gaze_x), int(gaze_y)),\n",
    "                radius=VIEWED_RADIUS,\n",
    "                color=(0, 0, 255),\n",
    "                thickness=2,\n",
    "            )\n",
    "\n",
    "        # Save the modified image back to its original location\n",
    "        cv2.imwrite(str(frame), frame_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564f9814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting video frames for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Loading gaze data for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Getting viewed annotations for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Processing 1147 annotations for class naaldcontainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1147/1147 [00:16<00:00, 67.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 868 annotations for class spuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 868/868 [00:12<00:00, 70.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1190 annotations for class keukenmes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [00:16<00:00, 70.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 208 annotations for class infuus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [00:03<00:00, 64.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1125 annotations for class stethoscoop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1125/1125 [00:17<00:00, 65.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 529 annotations for class snoep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 529/529 [00:08<00:00, 61.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1195 annotations for class iced tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1195/1195 [00:22<00:00, 53.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 977 annotations for class bril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 977/977 [00:22<00:00, 43.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 110 annotations for class rollator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:02<00:00, 41.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 380 annotations for class ampulevloeistof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:09<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 388 annotations for class ampulepoeder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 388/388 [00:08<00:00, 44.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ground truth for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Extracting video frames for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Loading gaze data for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Detected 3 gaze points for a frame in the video. This is unexpected.\n",
      "Getting viewed annotations for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Processing 715 annotations for class naaldcontainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 715/715 [00:10<00:00, 65.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 370 annotations for class spuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [00:06<00:00, 59.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 505 annotations for class keukenmes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [00:09<00:00, 52.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 590 annotations for class stethoscoop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 590/590 [00:09<00:00, 65.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 593 annotations for class bol wol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:07<00:00, 78.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 620 annotations for class snoep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 620/620 [00:08<00:00, 73.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 621 annotations for class nuchter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 621/621 [00:09<00:00, 66.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 711 annotations for class fotokader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 711/711 [00:10<00:00, 66.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 655 annotations for class iced tea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 655/655 [00:09<00:00, 67.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 635 annotations for class bril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [00:09<00:00, 67.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 760 annotations for class monitor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [00:11<00:00, 67.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 387 annotations for class ampulevloeistof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 387/387 [00:05<00:00, 67.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 507 annotations for class ampulepoeder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507/507 [00:07<00:00, 66.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ground truth for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Extracting video frames for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Loading gaze data for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Detected 3 gaze points for a frame in the video. This is unexpected.\n",
      "Getting viewed annotations for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Processing 862 annotations for class spuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 862/862 [00:11<00:00, 76.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 852 annotations for class keukenmes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:10<00:00, 77.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 951 annotations for class stethoscoop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [00:13<00:00, 69.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 873 annotations for class snoep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 873/873 [00:11<00:00, 79.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 64 annotations for class nuchter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 77.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 63 annotations for class fotokader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 75.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 973 annotations for class bril\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 973/973 [00:12<00:00, 78.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 281 annotations for class monitor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281/281 [00:03<00:00, 71.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 143 annotations for class rollator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143/143 [00:02<00:00, 69.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 840 annotations for class ampulevloeistof\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:10<00:00, 79.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 280 annotations for class ampulepoeder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:03<00:00, 81.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ground truth for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n"
     ]
    }
   ],
   "source": [
    "if not LABELING_VALIDATION_VIDEOS_PATH.exists():\n",
    "    os.makedirs(LABELING_VALIDATION_VIDEOS_PATH)\n",
    "else:\n",
    "    for file in LABELING_VALIDATION_VIDEOS_PATH.glob(\"*.mp4\"):\n",
    "        # os.remove(file)\n",
    "        pass\n",
    "\n",
    "if GROUND_TRUTH_PATH.exists():\n",
    "    GROUND_TRUTH_PATH.unlink()\n",
    "\n",
    "CREATE_VALIDATION_VIDEO = False\n",
    "gt_rows = []\n",
    "for recording_id in FULLY_LABELED_RECORDINGS:\n",
    "    with Session(engine) as session:\n",
    "        calibration_recording = simrooms_repo.get_calibration_recording(\n",
    "            db=session,\n",
    "            simroom_id=SIMROOM_ID,\n",
    "            recording_id=recording_id,\n",
    "        )\n",
    "        tracked_classes = simrooms_service.get_tracked_classes(\n",
    "            db=session, calibration_id=calibration_recording.id\n",
    "        )\n",
    "\n",
    "        trial_recording_path = calibration_recording.recording.video_path\n",
    "        gaze_data_path = calibration_recording.recording.gaze_data_path\n",
    "\n",
    "    # Extract video frames\n",
    "    print(f\"Extracting video frames for {recording_id}\")\n",
    "    frames, _ = simrooms_service.extract_tmp_frames(\n",
    "        recording_id=recording_id,\n",
    "    )\n",
    "\n",
    "    # Load and preprocess gaze points\n",
    "    print(f\"Loading gaze data for {recording_id}\")\n",
    "    gaze_position_per_frame = gaze_service.get_gaze_position_per_frame(\n",
    "        recording_id=recording_id,\n",
    "        frame_count=len(frames),\n",
    "    )\n",
    "\n",
    "    # Get all annotations that were viewed\n",
    "    print(f\"Getting viewed annotations for {recording_id}\")\n",
    "    annotations_per_frame = get_viewed_annotations_per_frame(\n",
    "        cal_rec_id=calibration_recording.id,\n",
    "        tracked_classes=tracked_classes,\n",
    "        gaze_position_per_frame=gaze_position_per_frame,\n",
    "    )\n",
    "\n",
    "    # Build the ground truth DataFrame\n",
    "    print(f\"Building ground truth for {recording_id}\")\n",
    "    for frame_idx, annotation_paths in annotations_per_frame.items():\n",
    "        for annotation_path in annotation_paths:\n",
    "            annotation_file = np.load(annotation_path)\n",
    "            class_id = int(annotation_file[\"class_id\"])\n",
    "            mask_area = np.sum(annotation_file[\"mask\"])\n",
    "            x1, y1, x2, y2 = annotation_file[\"box\"]\n",
    "            roi = annotation_file[\"roi\"]\n",
    "\n",
    "            laplacian_variance = cv2.Laplacian(roi, cv2.CV_64F).var()\n",
    "\n",
    "            gt_rows.append({\n",
    "                \"recording_id\": recording_id,\n",
    "                \"frame_idx\": frame_idx,\n",
    "                \"class_id\": class_id,\n",
    "                \"mask_area\": mask_area,\n",
    "                \"laplacian_variance\": laplacian_variance,\n",
    "                \"x1\": x1,\n",
    "                \"y1\": y1,\n",
    "                \"x2\": x2,\n",
    "                \"y2\": y2,\n",
    "            })\n",
    "\n",
    "    if CREATE_VALIDATION_VIDEO:\n",
    "        # Extract frames from the video and save them to a temporary directory\n",
    "        print(f\"Extracting frames for {recording_id}\")\n",
    "        tmp_frames_dir = tempfile.TemporaryDirectory()\n",
    "        tmp_frames_path = Path(tmp_frames_dir.name)\n",
    "        extract_frames_to_dir(\n",
    "            video_path=trial_recording_path,\n",
    "            frames_path=tmp_frames_path,\n",
    "            print_output=False,\n",
    "        )\n",
    "        frames = sorted(list(tmp_frames_path.glob(\"*.jpg\")), key=lambda x: int(x.stem))\n",
    "\n",
    "        print(f\"Drawing annotations for {recording_id}\")\n",
    "        draw_validation_video_frames(\n",
    "            frames=frames,\n",
    "            annotations_per_frame=annotations_per_frame,\n",
    "            gaze_position_per_frame=gaze_position_per_frame,\n",
    "            tracked_classes=tracked_classes,\n",
    "        )\n",
    "\n",
    "        print(f\"Creating video for {recording_id}\")\n",
    "        cmd = f'ffmpeg -hwaccel cuda -y -pattern_type glob -framerate {TOBII_GLASSES_FPS} -i \"{tmp_frames_path!s}/*.jpg\" -c:v libx264 -pix_fmt yuv420p \"{LABELING_VALIDATION_VIDEOS_PATH}/{recording_id}.mp4\"'\n",
    "        subprocess.run(\n",
    "            cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n",
    "        )\n",
    "\n",
    "ground_truth_df = pd.DataFrame(gt_rows)\n",
    "ground_truth_df.to_csv(\n",
    "    GROUND_TRUTH_PATH,\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorproef-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
