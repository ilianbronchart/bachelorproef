{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3115f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CHECKPOINTS_PATH\"] = \"../checkpoints\"\n",
    "\n",
    "import blur_detector\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy.orm import Session\n",
    "from src.api.db import engine\n",
    "from src.api.services import simrooms_service, labeling_service\n",
    "\n",
    "from experiment.settings import (\n",
    "    CLASS_ID_TO_NAME,\n",
    "    LABELING_REC_SAME_BACKGROUND_ID,\n",
    "    RECORDINGS_PATH,\n",
    "    BLUR_METRICS_PATH,\n",
    ")\n",
    "from src.utils import extract_frames_to_dir\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from concurrent.futures import as_completed, ThreadPoolExecutor\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692786c7",
   "metadata": {},
   "source": [
    "## Laplacian variance:\n",
    "\n",
    "Laplacian Variance measures image detail by evaluating the variance in pixel intensities, with a higher value indicating greater image sharpness \n",
    "\n",
    "## Spatially Varying Blur Detection\n",
    "\n",
    "See https://github.com/Utkarsh-Deshmukh/Spatially-Varying-Blur-Detection-python and the paper https://arxiv.org/pdf/1703.07478\n",
    "\n",
    "Generates a blur map, with higher intensities being sharper and lower intensities being blurry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43bf1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "def compute_robust_metrics(blur_map):\n",
    "    # Flatten the blur_map to a 1D array of high frequency coefficients.\n",
    "    h_freq_values = blur_map.flatten()\n",
    "\n",
    "    # Raw 90th percentile of the raw data.\n",
    "    raw_percentile90 = np.percentile(h_freq_values, 90)\n",
    "\n",
    "    # Winsorize the data by clipping the lower 5% and upper 95% of the values.\n",
    "    lower_bound = np.percentile(h_freq_values, 5)\n",
    "    upper_bound = np.percentile(h_freq_values, 95)\n",
    "    winsorized = np.clip(h_freq_values, lower_bound, upper_bound)\n",
    "    winsorized_90 = np.percentile(winsorized, 90)\n",
    "\n",
    "    # Calculate a 10% trimmed mean (dropping 10% of the extreme values on each tail).\n",
    "    trimmed = trim_mean(h_freq_values, proportiontocut=0.1)\n",
    "\n",
    "    # Compute the median.\n",
    "    median_val = np.median(h_freq_values)\n",
    "\n",
    "    # Compute the median absolute deviation (MAD).\n",
    "    mad_val = np.median(np.abs(h_freq_values - median_val))\n",
    "\n",
    "    return {\n",
    "        \"raw_percentile90\": raw_percentile90,\n",
    "        \"winsorized_90\": winsorized_90,\n",
    "        \"trimmed_mean\": trimmed,\n",
    "        \"median\": median_val,\n",
    "        \"mad\": mad_val,\n",
    "    }\n",
    "\n",
    "\n",
    "# Define a function to process a single annotation file.\n",
    "def process_frame(frame_path: Path):\n",
    "    frame_idx = int(frame_path.stem)\n",
    "    frame = cv2.imread(frame_path)\n",
    "    # grame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # blur_map = blur_detector.detectBlur(\n",
    "    #     grame_gray,\n",
    "    #     downsampling_factor=1,\n",
    "    #     num_scales=4,\n",
    "    #     scale_start=1,\n",
    "    #     show_progress=False,\n",
    "    # )\n",
    "    laplacian_variance = cv2.Laplacian(frame, cv2.CV_64F).var()\n",
    "\n",
    "    # Basic variance metric.\n",
    "    # blur_var = blur_map.var()\n",
    "\n",
    "    # # Compute robust metrics from the blur_map.\n",
    "    # robust_metrics = compute_robust_metrics(blur_map)\n",
    "\n",
    "    # Build the result dictionary with all the metrics.\n",
    "    result = {\n",
    "        \"frame_idx\": frame_idx,\n",
    "        \"laplacian_variance\": laplacian_variance,\n",
    "        # \"blur_var\": blur_var,\n",
    "        # \"raw_percentile90\": robust_metrics[\"raw_percentile90\"],\n",
    "        # \"winsorized_90\": robust_metrics[\"winsorized_90\"],\n",
    "        # \"trimmed_mean\": robust_metrics[\"trimmed_mean\"],\n",
    "        # \"median\": robust_metrics[\"median\"],\n",
    "        # \"mad\": robust_metrics[\"mad\"],\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa3f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 5235be94-da01-43b5-8827-92a51d32ce30\n",
      "Calculating blur metrics for 5235be94-da01-43b5-8827-92a51d32ce30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 5235be94-da01-43b5-8827-92a51d32ce30: 100%|██████████| 1368/1368 [00:20<00:00, 66.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for d6fd0aed-b901-4863-bad8-7910dad693e0\n",
      "Calculating blur metrics for d6fd0aed-b901-4863-bad8-7910dad693e0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording d6fd0aed-b901-4863-bad8-7910dad693e0: 100%|██████████| 14121/14121 [03:07<00:00, 75.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for d50c5f3b-2822-4462-9880-5a8f0dd46bfb\n",
      "Calculating blur metrics for d50c5f3b-2822-4462-9880-5a8f0dd46bfb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording d50c5f3b-2822-4462-9880-5a8f0dd46bfb: 100%|██████████| 1500/1500 [00:18<00:00, 82.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 67b71a70-da64-467a-9fb6-91bc29265fd1\n",
      "Calculating blur metrics for 67b71a70-da64-467a-9fb6-91bc29265fd1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 67b71a70-da64-467a-9fb6-91bc29265fd1: 100%|██████████| 2064/2064 [00:28<00:00, 72.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n",
      "Calculating blur metrics for b8eeecc0-06b1-47f7-acb5-89aab3c1724d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording b8eeecc0-06b1-47f7-acb5-89aab3c1724d: 100%|██████████| 1557/1557 [00:21<00:00, 70.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for b214c60b-7521-495b-a699-e223da0c77c1\n",
      "Calculating blur metrics for b214c60b-7521-495b-a699-e223da0c77c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording b214c60b-7521-495b-a699-e223da0c77c1: 100%|██████████| 1440/1440 [00:20<00:00, 70.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 6f3e2ccf-51f6-4377-8b84-63a3c16928a8\n",
      "Calculating blur metrics for 6f3e2ccf-51f6-4377-8b84-63a3c16928a8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 6f3e2ccf-51f6-4377-8b84-63a3c16928a8: 100%|██████████| 1458/1458 [00:17<00:00, 83.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for b8f453aa-5a12-4cbb-a0ec-20eb503f8797\n",
      "Calculating blur metrics for b8f453aa-5a12-4cbb-a0ec-20eb503f8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording b8f453aa-5a12-4cbb-a0ec-20eb503f8797: 100%|██████████| 1364/1364 [00:19<00:00, 69.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 2fe01600-c057-40ee-8434-4e9e0688ca2d\n",
      "Calculating blur metrics for 2fe01600-c057-40ee-8434-4e9e0688ca2d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 2fe01600-c057-40ee-8434-4e9e0688ca2d: 100%|██████████| 2041/2041 [00:28<00:00, 72.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 98128cdc-ffeb-40cb-9528-573e25028e87\n",
      "Calculating blur metrics for 98128cdc-ffeb-40cb-9528-573e25028e87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 98128cdc-ffeb-40cb-9528-573e25028e87: 100%|██████████| 1543/1543 [00:21<00:00, 70.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 7ae61789-7a26-4c31-abef-4ab49a34abfd\n",
      "Calculating blur metrics for 7ae61789-7a26-4c31-abef-4ab49a34abfd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 7ae61789-7a26-4c31-abef-4ab49a34abfd: 100%|██████████| 1358/1358 [00:16<00:00, 84.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 9fa3e3b8-ed94-4b06-ba49-e66e3997d710\n",
      "Calculating blur metrics for 9fa3e3b8-ed94-4b06-ba49-e66e3997d710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 9fa3e3b8-ed94-4b06-ba49-e66e3997d710: 100%|██████████| 1229/1229 [00:18<00:00, 68.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 73ce8a30-ccc6-4514-b978-f8b5844be16b\n",
      "Calculating blur metrics for 73ce8a30-ccc6-4514-b978-f8b5844be16b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 73ce8a30-ccc6-4514-b978-f8b5844be16b: 100%|██████████| 11003/11003 [02:26<00:00, 75.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n",
      "Calculating blur metrics for 32f02db7-adc0-4556-a2da-ed2ba60a58c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 32f02db7-adc0-4556-a2da-ed2ba60a58c9: 100%|██████████| 1365/1365 [00:19<00:00, 70.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 67823ccd-a1f0-4cde-b954-3b9e5fe160c1\n",
      "Calculating blur metrics for 67823ccd-a1f0-4cde-b954-3b9e5fe160c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 67823ccd-a1f0-4cde-b954-3b9e5fe160c1: 100%|██████████| 1554/1554 [00:18<00:00, 85.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames for 89b60530-e0e4-4f5d-9ee6-af85c8d99ff4\n",
      "Calculating blur metrics for 89b60530-e0e4-4f5d-9ee6-af85c8d99ff4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames for recording 89b60530-e0e4-4f5d-9ee6-af85c8d99ff4: 100%|██████████| 1270/1270 [00:15<00:00, 82.74it/s]\n"
     ]
    }
   ],
   "source": [
    "if BLUR_METRICS_PATH.exists():\n",
    "    shutil.rmtree(BLUR_METRICS_PATH)\n",
    "BLUR_METRICS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "recordings = list(RECORDINGS_PATH.glob(\"*.mp4\"))\n",
    "if len(recordings) != 16:\n",
    "    raise ValueError(f\"Expected 16 recordings, found {len(recordings)}\")\n",
    "\n",
    "# For every annotated class in the recording:\n",
    "for recording_path in recordings:\n",
    "    recording_id = recording_path.stem\n",
    "\n",
    "    print(f\"Extracting frames for {recording_id}\")\n",
    "    tmp_frames_dir = tempfile.TemporaryDirectory()\n",
    "    tmp_frames_path = Path(tmp_frames_dir.name)\n",
    "    extract_frames_to_dir(\n",
    "        video_path=recording_path,\n",
    "        frames_path=tmp_frames_path,\n",
    "        print_output=False,\n",
    "    )\n",
    "    frames = sorted(list(tmp_frames_path.glob(\"*.jpg\")), key=lambda x: int(x.stem))\n",
    "\n",
    "    print(f\"Calculating blur metrics for {recording_id}\")\n",
    "    result_rows = []\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        future_to_path = {\n",
    "            executor.submit(process_frame, frame_path): frame_path\n",
    "            for frame_path in frames\n",
    "        }\n",
    "\n",
    "        # As each future completes, gather its results.\n",
    "        for future in tqdm(\n",
    "            as_completed(future_to_path),\n",
    "            total=len(future_to_path),\n",
    "            desc=f\"Processing frames for recording {recording_id}\",\n",
    "        ):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                result_rows.append(result)\n",
    "            except Exception as exc:\n",
    "                failed_path = future_to_path[future]\n",
    "                print(f\"Error processing {failed_path}: {exc}\")\n",
    "\n",
    "    # Create a DataFrame with the collected results.\n",
    "    result_df = pd.DataFrame(result_rows)\n",
    "    result_df.to_csv(BLUR_METRICS_PATH / f\"{recording_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "plt.figure(figsize=(30, 7))\n",
    "plt.plot(frame_indexes, laplacian_vars)\n",
    "plt.title(\"Laplacian variance per frame\")\n",
    "plt.xlabel(\"Frame index\")\n",
    "plt.ylabel(\"Laplacian variance\")\n",
    "plt.show()\n",
    "\n",
    "# plot a histogram of the laplacian variance\n",
    "plt.figure(figsize=(15, 7))\n",
    "counts, bin_edges, patches = plt.hist(\n",
    "    laplacian_vars, bins=100\n",
    ")  # Using 100 bins as in your example\n",
    "plt.title(\"Laplacian variance histogram\")\n",
    "plt.xlabel(\"Laplacian variance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "import random\n",
    "\n",
    "if not isinstance(laplacian_vars, np.ndarray):\n",
    "    laplacian_vars = np.array(laplacian_vars)\n",
    "\n",
    "# 1. Define the overall variance range and bin properties\n",
    "min_overall_variance = 0.0\n",
    "max_overall_variance = 5.0\n",
    "bin_width = 1.0\n",
    "num_examples_per_bin = 10\n",
    "\n",
    "# Create bin edges (e.g., [0.0, 1.0, 2.0, ..., 10.0])\n",
    "# Use arange for float steps, then ensure the max_overall_variance is included if it's a multiple of bin_width\n",
    "bin_edges = np.arange(min_overall_variance, max_overall_variance + bin_width, bin_width)\n",
    "# Ensure the last edge doesn't slightly exceed max_overall_variance due to float precision if it was meant to be exact\n",
    "if bin_edges[-1] > max_overall_variance and np.isclose(\n",
    "    bin_edges[-1], max_overall_variance\n",
    "):\n",
    "    bin_edges[-1] = max_overall_variance\n",
    "elif (\n",
    "    bin_edges[-1] < max_overall_variance\n",
    "    and len(bin_edges) * bin_width - bin_width < max_overall_variance\n",
    "):  # if arange stopped short\n",
    "    # This case is less likely with + bin_width, but good to be aware\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Defined bins for variance range [{min_overall_variance}, {max_overall_variance}) with width {bin_width}:\"\n",
    ")\n",
    "# Bin definitions: [start, end)\n",
    "target_bins = []\n",
    "for i in range(len(bin_edges) - 1):\n",
    "    bin_start = bin_edges[i]\n",
    "    bin_end = bin_edges[i + 1]\n",
    "    # Ensure we don't exceed the overall max, especially for the last bin\n",
    "    if (\n",
    "        bin_start < max_overall_variance\n",
    "    ):  # only consider bins that start before the overall max\n",
    "        target_bins.append({\n",
    "            \"start\": bin_start,\n",
    "            \"end\": min(bin_end, max_overall_variance),\n",
    "        })\n",
    "        print(\n",
    "            f\"  Bin {i}: [{target_bins[-1]['start']:.1f}, {target_bins[-1]['end']:.1f})\"\n",
    "        )\n",
    "\n",
    "\n",
    "# 2. Collect examples for each target bin\n",
    "all_selected_examples_by_bin = {}  # To store lists of {'path': Path, 'variance': float}\n",
    "\n",
    "for i, bin_info in enumerate(target_bins):\n",
    "    bin_start, bin_end = bin_info[\"start\"], bin_info[\"end\"]\n",
    "    bin_label = f\"[{bin_start:.1f}-{bin_end:.1f})\"\n",
    "\n",
    "    # Find frames that fall within this specific bin\n",
    "    # Note: The upper limit of the bin is exclusive (var < bin_end)\n",
    "    # For the very last bin that should include max_overall_variance, adjust if needed,\n",
    "    # but typically ranges are [start, end).\n",
    "    # If bin_end is exactly max_overall_variance, we want var < max_overall_variance or var <= max_overall_variance\n",
    "    # Let's stick to [start, end) for consistency.\n",
    "\n",
    "    current_bin_frames_data = []\n",
    "    for frame_idx, var_val in enumerate(laplacian_vars):\n",
    "        # Check if var_val is in [bin_start, bin_end)\n",
    "        if bin_start <= var_val < bin_end:\n",
    "            current_bin_frames_data.append({\n",
    "                \"path\": frames[frame_idx],\n",
    "                \"variance\": var_val,\n",
    "            })\n",
    "\n",
    "    # Select random examples from this bin\n",
    "    if current_bin_frames_data:\n",
    "        if len(current_bin_frames_data) > num_examples_per_bin:\n",
    "            all_selected_examples_by_bin[bin_label] = random.sample(\n",
    "                current_bin_frames_data, num_examples_per_bin\n",
    "            )\n",
    "        else:\n",
    "            all_selected_examples_by_bin[bin_label] = (\n",
    "                current_bin_frames_data  # Show all if fewer\n",
    "            )\n",
    "    else:\n",
    "        all_selected_examples_by_bin[bin_label] = []  # No images in this bin\n",
    "        print(f\"No images found for bin {bin_label}\")\n",
    "\n",
    "\n",
    "# 3. Plot the selected example images\n",
    "num_bins_with_examples = sum(\n",
    "    1 for ex_list in all_selected_examples_by_bin.values() if ex_list\n",
    ")\n",
    "\n",
    "if num_bins_with_examples > 0:\n",
    "    # Plot each bin's examples in a separate figure row or figure for clarity\n",
    "    # Let's try one figure with multiple rows, one row per bin. Max 5 images per row.\n",
    "\n",
    "    # Calculate total number of images to plot to set up the figure\n",
    "    total_images_to_plot = sum(\n",
    "        len(ex_list) for ex_list in all_selected_examples_by_bin.values()\n",
    "    )\n",
    "\n",
    "    if total_images_to_plot == 0:\n",
    "        print(\"No example images to plot.\")\n",
    "    else:\n",
    "        # Max 5 columns (for the 5 examples per bin)\n",
    "        cols = num_examples_per_bin\n",
    "        # Number of rows is the number of bins that have examples\n",
    "        rows = num_bins_with_examples\n",
    "\n",
    "        fig_height_per_row = 3  # inches\n",
    "        fig_width_per_col = 3  # inches\n",
    "        plt.figure(figsize=(cols * fig_width_per_col, rows * fig_height_per_row))\n",
    "\n",
    "        plot_idx = 1  # Global plot index for subplots\n",
    "        current_row_title_y = 0.9  # Initial Y for row titles\n",
    "\n",
    "        bin_counter = 0\n",
    "        for bin_label, examples in all_selected_examples_by_bin.items():\n",
    "            if not examples:\n",
    "                continue  # Skip bins with no examples\n",
    "\n",
    "            # Add a title for this bin's row of images (optional, can get crowded)\n",
    "            # For simplicity, we'll just ensure titles are on individual plots.\n",
    "\n",
    "            for example_data in examples:\n",
    "                example_image_path = example_data[\"path\"]\n",
    "                actual_variance = example_data[\"variance\"]\n",
    "\n",
    "                img = cv2.imread(str(example_image_path))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                ax = plt.subplot(rows, cols, plot_idx)\n",
    "                plt.imshow(img)\n",
    "\n",
    "                # Add bin label to the title of the first image in the row for context\n",
    "                if (plot_idx - 1) % cols == 0:\n",
    "                    ax.set_title(\n",
    "                        f\"Bin: {bin_label}\\nVar: {actual_variance:.2f}\", fontsize=9\n",
    "                    )\n",
    "                else:\n",
    "                    ax.set_title(f\"Var: {actual_variance:.2f}\", fontsize=9)\n",
    "                plt.axis(\"off\")\n",
    "                plot_idx += 1\n",
    "\n",
    "            # Fill remaining columns in the row if fewer than num_examples_per_bin were shown\n",
    "            while (plot_idx - 1) % cols != 0 and plot_idx <= rows * cols:\n",
    "                # Add an empty subplot to maintain grid structure if a bin has < 5 examples\n",
    "                ax = plt.subplot(rows, cols, plot_idx)\n",
    "                ax.axis(\"off\")  # Make it invisible\n",
    "                plot_idx += 1\n",
    "\n",
    "            bin_counter += 1\n",
    "\n",
    "        plt.suptitle(\n",
    "            f\"Example Images from Laplacian Variance Bins in Range [{min_overall_variance:.1f}, {max_overall_variance:.1f})\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        plt.tight_layout(rect=[0, 0.02, 1, 0.96])  # Adjust layout\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\n",
    "        f\"No frames found with Laplacian variance between {min_overall_variance} and {max_overall_variance} to pick examples from.\"\n",
    "    )\n",
    "\n",
    "# You might also want to see the histogram again to understand where these ranges fall\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.hist(laplacian_vars, bins=100, label=\"All Variances\", zorder=1)\n",
    "# Highlight the selected BINS on the histogram\n",
    "for i, bin_info in enumerate(target_bins):\n",
    "    color = plt.cm.get_cmap(\"viridis\", len(target_bins))(\n",
    "        i\n",
    "    )  # Different color for each bin span\n",
    "    plt.axvspan(\n",
    "        bin_info[\"start\"],\n",
    "        bin_info[\"end\"],\n",
    "        color=color,\n",
    "        alpha=0.3,\n",
    "        zorder=2,\n",
    "        label=f\"Bin [{bin_info['start']:.1f}-{bin_info['end']:.1f})\"\n",
    "        if i % 2 == 0\n",
    "        else None,\n",
    "    )  # Label every other to avoid clutter\n",
    "plt.title(\"Laplacian Variance Histogram with Target Bins Highlighted\")\n",
    "plt.xlabel(\"Laplacian Variance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# plt.legend() # Can be too cluttered with many bins, enable if needed\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelorproef-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
