{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a111f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:31:49.051694: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 17:31:49.211665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744039909.273034   11280 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744039909.289846   11280 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-07 17:31:49.435226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.api.controllers.generate_embeddings as generate_embeddings\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from sqlalchemy.orm import Session\n",
    "from src.config import GAZE_FOVEA_FOV, TOBII_FOV_X\n",
    "from src.db import engine\n",
    "from src.db.models import Recording, SimRoomClass\n",
    "from src.api.controllers.gaze_segmentation import (\n",
    "    get_gaze_points,\n",
    "    match_frames_to_gaze,\n",
    "    parse_gazedata_file,\n",
    "    mask_was_viewed\n",
    ")\n",
    "from src.utils import cv2_video_fps, cv2_video_frame_count, cv2_video_resolution\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from ultralytics import FastSAM\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e84946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiment_metadata.json\") as file:\n",
    "    experiment_metadata = json.load(file)\n",
    "    trial_recordings_metadata = experiment_metadata[\"trial_recordings_metadata\"]\n",
    "    trial_recording_uuids = list(trial_recordings_metadata.keys())\n",
    "    labeling_same_background_uuid = experiment_metadata[\"labeling_same_background_uuid\"]\n",
    "    labeling_diff_background_uuid = experiment_metadata[\"labeling_diff_background_uuid\"]\n",
    "\n",
    "with Session(engine) as session:\n",
    "    trial_recordings = (\n",
    "        session.query(Recording).filter(Recording.uuid.in_(trial_recording_uuids)).all()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5231553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dinov2 = generate_embeddings.load_model()\n",
    "GAZE_SEGMENTATION_RESULTS_PATH = Path(\"data/gaze_segmentation_results\")\n",
    "SAME_BACKGROUND_VECTOR_INDEXES_PATH = Path(\"data/vector_indexes/same_background\")\n",
    "DIFF_BACKGROUND_VECTOR_INDEXES_PATH = Path(\"data/vector_indexes/diff_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37331195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grounding_dataset(dataset_path: Path, gaze_segmentation_results: list[Any], index: faiss.IndexIDMap, k: int):\n",
    "    result_rows = []\n",
    "    for result in gaze_segmentation_results:\n",
    "        frame_idx = result[\"frame_idx\"]\n",
    "        rois = result[\"rois\"]\n",
    "        object_ids = result[\"object_ids\"]\n",
    "\n",
    "        # Get embeddings (assuming one batch is returned)\n",
    "        embeddings, _, _ = list(generate_embeddings.get_embeddings(dinov2, rois))[0]\n",
    "        per_roi_distances, per_roi_class_ids = generate_embeddings.search_index(\n",
    "            index, embeddings, k=k\n",
    "        )\n",
    "\n",
    "        for i, roi in enumerate(rois):  # iterate over each ROI\n",
    "            object_id = object_ids[i]\n",
    "            distances = per_roi_distances[i]\n",
    "            class_ids = per_roi_class_ids[i]\n",
    "\n",
    "            # Group distances by class using defaultdict for conciseness\n",
    "            class_to_dists = defaultdict(list)\n",
    "            for cid, d in zip(class_ids, distances, strict=False):\n",
    "                class_to_dists[cid].append(d)\n",
    "\n",
    "            # For each class, compute statistics and add a row\n",
    "            for cid, dists in class_to_dists.items():\n",
    "                result_rows.append({\n",
    "                    \"frame_idx\": frame_idx,\n",
    "                    \"object_id\": object_id,\n",
    "                    \"class_id\": cid,\n",
    "                    \"avg_distance\": np.mean(dists),\n",
    "                    \"min_distance\": np.min(dists),\n",
    "                    \"max_distance\": np.max(dists),\n",
    "                    \"var_distance\": np.var(dists),\n",
    "                })\n",
    "\n",
    "    pd.DataFrame(result_rows).to_csv(dataset_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97f7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:   0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:   7%|▋         | 1/14 [14:07<3:03:42, 847.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  14%|█▍        | 2/14 [22:25<2:08:25, 642.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  21%|██▏       | 3/14 [31:39<1:50:16, 601.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  29%|██▊       | 4/14 [41:40<1:40:12, 601.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  36%|███▌      | 5/14 [53:17<1:35:24, 636.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  43%|████▎     | 6/14 [1:04:05<1:25:20, 640.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  50%|█████     | 7/14 [1:12:49<1:10:15, 602.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  57%|█████▋    | 8/14 [1:20:52<56:25, 564.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  64%|██████▍   | 9/14 [1:30:04<46:41, 560.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  71%|███████▏  | 10/14 [1:37:14<34:40, 520.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n",
      "Processing k=100 for sample_count=600\n",
      "Processing k=200 for sample_count=600\n",
      "Processing k=300 for sample_count=600\n",
      "Processing k=400 for sample_count=600\n",
      "Processing k=500 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=400\n",
      "Processing k=100 for sample_count=400\n",
      "Processing k=200 for sample_count=400\n",
      "Processing k=300 for sample_count=400\n",
      "Processing k=400 for sample_count=400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=500 for sample_count=400\n",
      "Processing k=50 for sample_count=500\n",
      "Processing k=100 for sample_count=500\n",
      "Processing k=200 for sample_count=500\n",
      "Processing k=300 for sample_count=500\n",
      "Processing k=400 for sample_count=500\n",
      "Processing k=500 for sample_count=500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  79%|███████▊  | 11/14 [1:48:16<28:10, 563.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=50 for sample_count=200\n",
      "Processing k=100 for sample_count=200\n",
      "Processing k=200 for sample_count=200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=300 for sample_count=200\n",
      "Processing k=400 for sample_count=200\n",
      "Processing k=500 for sample_count=200\n",
      "Processing k=50 for sample_count=300\n",
      "Processing k=100 for sample_count=300\n",
      "Processing k=200 for sample_count=300\n",
      "Processing k=300 for sample_count=300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=400 for sample_count=300\n",
      "Processing k=500 for sample_count=300\n",
      "Processing k=50 for sample_count=100\n",
      "Processing k=100 for sample_count=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=200 for sample_count=100\n",
      "Processing k=300 for sample_count=100\n",
      "Processing k=400 for sample_count=100\n",
      "Processing k=500 for sample_count=100\n",
      "Processing k=50 for sample_count=600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing trial recordings:  79%|███████▊  | 11/14 [1:51:00<30:16, 605.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11280/3066527482.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msample_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mgrounding_dataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrounding_datasets_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"grounding_dataset_k={k}_samples={sample_count}.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             create_grounding_dataset(\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrounding_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mgaze_segmentation_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgaze_segmentation_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11280/183664373.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(dataset_path, gaze_segmentation_results, index, k)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mobject_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"object_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Get embeddings (assuming one batch is returned)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdinov2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         per_roi_distances, per_roi_class_ids = generate_embeddings.search_index(\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/bachelorproef/src/api/controllers/generate_embeddings.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(index, embeddings, k)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexIDMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_L2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/bachelorproef/.venv/lib/python3.10/site-packages/faiss/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, x, k, D, I)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/bachelorproef/.venv/lib/python3.10/site-packages/faiss/swigfaiss.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, n, x, k, distances, labels)\u001b[0m\n\u001b[1;32m   8403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexIDMap_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_recording(recording_uuid: str, index: faiss.IndexIDMap, k: int):\n",
    "    gaze_segmentation_results_path = GAZE_SEGMENTATION_RESULTS_PATH / recording_uuid\n",
    "\n",
    "    gaze_segmentation_results = list(gaze_segmentation_results_path.iterdir())\n",
    "    gaze_segmentation_results.sort(key=lambda x: int(x.stem))\n",
    "    gaze_segmentation_results = [\n",
    "        np.load(result, allow_pickle=True) for result in gaze_segmentation_results\n",
    "    ]\n",
    "    # Further processing can be done here using the 'index' and 'k' if needed.\n",
    "\n",
    "K_OPTIONS = [50] #, 100, 200, 300, 400, 500]\n",
    "GROUNDING_DATASETS_PATH = Path(\"data/grounding_datasets\")\n",
    "\n",
    "for trial_recording in tqdm(trial_recordings, desc=\"Processing trial recordings\"):\n",
    "    # Load gaze segmentation results for this recording\n",
    "    gaze_segmentation_results_path = GAZE_SEGMENTATION_RESULTS_PATH / trial_recording.uuid\n",
    "    gaze_segmentation_results = list(gaze_segmentation_results_path.iterdir())\n",
    "    gaze_segmentation_results.sort(key=lambda x: int(x.stem))\n",
    "    gaze_segmentation_results = [\n",
    "        np.load(result, allow_pickle=True) for result in gaze_segmentation_results\n",
    "    ]\n",
    "\n",
    "    # Create the grounding datasets directory for this recording\n",
    "    grounding_datasets_path = GROUNDING_DATASETS_PATH / trial_recording.uuid\n",
    "    if grounding_datasets_path.exists():\n",
    "        shutil.rmtree(grounding_datasets_path)\n",
    "    grounding_datasets_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create grounding datasets for each index and for each k value\n",
    "    vector_index_paths = list(SAME_BACKGROUND_VECTOR_INDEXES_PATH.iterdir())\n",
    "    for vector_index_path in tqdm(vector_index_paths, desc=\"Processing vector indexes\", leave=False):\n",
    "        sample_count = int(vector_index_path.name.split(\"_\")[0])\n",
    "        index = faiss.read_index(str(vector_index_path))\n",
    "\n",
    "        for k in K_OPTIONS:\n",
    "            if k > sample_count:\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing k={k} for sample_count={sample_count}\")\n",
    "            grounding_dataset_path = grounding_datasets_path / f\"grounding_dataset_k={k}_samples={sample_count}.csv\"\n",
    "            create_grounding_dataset(\n",
    "                dataset_path=grounding_dataset_path,\n",
    "                gaze_segmentation_results=gaze_segmentation_results,\n",
    "                index=index,\n",
    "                k=k,\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
