%---------- Inleiding ---------------------------------------------------------

\section{Inleiding}%
\label{sec:inleiding}

Observatievaardigheden van zorgverleners\newline
zijn belangrijk om nauwkeurige diagnoses te stellen
en effectieve zorgplannen te ontwikkelen.
In het 360° Zorglab aan HOGENT worden studenten getraind via simulaties waarbij
hun oogbewegingen worden geregistreerd met Tobii Glasses.
Een belangrijk aspect van deze training is dat studenten leren om kritische objecten,
zoals een colafles op het nachtkastje van een diabetespatiënt, op te merken. 
\par
Hoewel de Tobii Glasses bruikbare eyetracking data leveren, ontbreekt er momenteel geschikte software om te analyseren of studenten daadwerkelijk naar deze objecten hebben gekeken.
Dit gebrek aan dataverwerking en visualisatie maakt het voor trainers lastig om de observatieprestaties van studenten efficiënt te beoordelen en te verbeteren. 
Zonder een geautomatiseerde manier om te detecteren welke specifieke objecten studenten wel of niet hebben waargenomen,\newline wordt het geven van directe feedback een tijdrovend proces.
\par
Om dit probleem aan te pakken, richt dit bachelorproefonderzoek zich op het beantwoorden van de volgende onderzoeksvraag:

\textit{"Hoe kan objectdetectie- en segmentatiesoftware geïntegreerd worden met eyetrackingdata van Tobii Glasses om observatieprestaties van studenten in het 360° Zorglab automatisch te analyseren en te visualiseren?"}

Deze onderzoeksvraag wordt uitgewerkt aan de hand van de volgende deelvragen:
\begin{enumerate}
    \item Welke bestaande objectdetectie en seg- \newline mentatie modellen zijn hiervoor geschikt?
    \item Welke preprocessing- en fine-tuning \newline methoden zijn nodig om Zorglab-specifieke data effectief te gebruiken met deze modellen?
    \item Hoe kan een softwareoplossing ontwikkeld worden voor een gebruiksvriendelijke analyse en visualisatie van eyetrackingdata?
    \item In welke mate kunnen de modellen en de ontwikkelde software een nauwkeurige evaluatie van kritische objectwaarnemingen \newline garanderen?
\end{enumerate}
\par
Het doel is om trainers in het Zorglab te ondersteunen bij het analyseren en visualiseren van deze data, zodat ze snel inzicht krijgen in de observatieprestaties van studenten en kunnen vaststellen of belangrijke objecten tijdens zorgsimulaties zijn waargenomen.

%---------- Stand van zaken ---------------------------------------------------

\section{Stand van zaken}%
\label{sec:literatuurstudie}

\subsection{Bestaande Implementaties}

Recente ontwikkelingen in deep learning hebben de toepassingen van eye-tra\-cking aanzienlijk versterkt, vooral op het gebied van objectdetectie in dynamische en complexe omgevingen.
\par
\textcite{Cho2024} introduceerden het ISGOD systeem, dat oogbewegingen en objectdetectie 
integreert voor kwaliteitsinspectie in productieomgevingen, waarbij real-time analyse mogelijk ge\-maakt wordt ondanks variabele posities en bewegingen. 

\textcite{Cederin2023} onderzochten automatische objectdetectie en tracking in eye tracking analyses en verbeterden de nauwkeurigheid 
door motion deblurring technieken toe te passen, zoals DeblurGAN-v2 gecombineerd met objectdetectoren en trackers. 

Daarnaast combineerde \textcite{Kulyk2023} objectdetectie met eye-tracking data in een virtuele kunsttentoonstelling 
om bezoekersinteresses en visuele aandachtspunten te identificeren. 

\subsection{Machine-learning Modellen}

Naast geïntegreerde eye-tracking systemen, maken de onderzochte studies gebruik van diverse objectdetectiemodellen. 
\par
\textcite{Kulyk2023} maakte gebruik van het Faster R-CNN netwerk, een Convolutioneel Neuronaal Netwerk (CNN) dat 
bekend staat om zijn hoge nauwkeurigheid bij objectdetectie.

\textcite{Cederin2023} breidden hun onderzoek uit door 
naast Faster R-CNN ook andere CNN-gebaseerde architecturen zoals Feature Pyramid Network (FPN), Spatial Pyramid Pooling Network (SPP-Net), 
You Only Look Once (YOLO) en Single Shot MultiBox Detector (SSD) te evalueren. 
Ze onderzochten ook transformer gebaseerde modellen zoals DEtection TRansformer (DETR) en DINO, 
die recentelijk aanzienlijke verbeteringen hebben laten zien in het omgaan met complexe en dynamische scènes.
\par
\textcite{Liu2023} introduceerden in 2023 Grounding DINO, een voorgetraind model dat objecten in afbeeldingen kan detecteren op basis van tekstprompts.
Dit model zou eventueel objecten binnen het Zorglab kunnen detecteren zonder fine-tuning op specifieke data, wat de gebruiksvriendelijkheid van de software zou verbeteren.
\par
Dit bachelorproefonderzoek zal verder gaan dan alleen objectdetectie door ook segmentatiemodellen te verkennen 
die mogelijk via finetuning en tekstprompting specifiek kunnen worden aangepast aan de use case van het 360° Zorglab. 

Een veelbelovend model hiervoor is Meta’s\newline segment Anything Model 2 \autocite{Ravi2024},\newline dat in de medische context succesvol is toegepast door \textcite{Zhu2024}
binnen Medical SAM 2 (MedSAM-2) voor zowel 2D als 3D medische beeldsegmentatie via één enkele prompt. 

\textcite{Wang2023} ontwikkelden GazeSAM, dat eye-tracking 
data gebruikt als inputprompt voor SAM om real-time segmentatiemasks te genereren.

Daarnaast biedt het state-of-the-art werk van \textcite{Bagchi2024} met het ReferEverything framework een model voor het segmenteren van concepten in 
videodata via natuurlijke taal-\newline beschrijvingen, wat relevant kan zijn voor het verwerken van de dynamische videodata van Tobii Glasses.
Momenteel is de code van ReferEverything nog niet beschikbaar, maar de onderzoekers hebben aangegeven dat deze binnenkort open-source zal worden gemaakt.

% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

De bachelorproef zal worden uitgevoerd\newline volgens een agile aanpak, waarbij iteratieve cycli (sprints) 
en overlappende fasen worden gebruikt om flexibiliteit en continue verbetering mogelijk te maken. 
Deze aanpak zorgt ervoor dat verschillende onderdelen van het project parallel kunnen verlopen en snel 
kunnen worden aangepast op basis van tussentijdse bevindingen. Nieuwe taken worden doorheen de sprints toegevoegd 
aan een backlog binnen een Trello-bord, en worden doorheen de sprints opgepakt en afgerond.
\par
Het doel voor de PoC is om een user-flow te ontwikkelen die het mogelijk maakt om de volgende zaken uit te voeren:
\begin{itemize}
    \item 1. Het ophalen van eyetrackingdata van de Tobii Glasses
    \item 2. Het definiëren van kritische objecten die geobserveerd moeten worden.
    \item 3. Het analyseren van van de data met\newline objectdetectie- en segmentatiemodellen.\newline
    Deze stap wordt hierna de data-architectuur genoemd.
    \item 4. Het al dan niet manueel wegfilteren van vals-positieve objectdetecties.
    \item 5. Het visualiseren van de resultaten van de analyse via een metriek die de blik-punten van de studenten koppelt aan de gedetecteerde objecten.
\end{itemize}
\par
De voorkeur gaat naar het gebruik van voorgetrainde modellen om de nood aan hertrainen te minimaliseren en zo de gebruikerservaring te verbeteren.
Indien nodig kan de PoC uitgebreid worden met extra functionaliteiten zoals het finetunen van modellen met simulatiespecifieke data.

%---------- Tijdsplanning ------------------------------------------------------
\section{Tijdsplanning}
De bachelorproef is gepland van 10 februari 2025 tot en met 23 mei 2025, met een totaal van 7 sprints van 2 weken.
De activiteiten binnen elke sprint omvatten, in geen specifieke volgorde:
\begin{itemize}
    \item Literatuurstudie
    \item Dataverzameling en labeling
    \item Modelselectie en implementatie
    \item Schrijven van Python Notebooks voor experimenten
    \item Ontwikkelen van de data-architectuur binnen de PoC
    \item Ontwikkelen van de user interface voor de PoC
    \item Uitbreiding van de PoC met nieuwe functionaliteiten
    \item Unit-testen schrijven voor de PoC
    \item Meetings met de co-promotor voor\newline feedback en verfijning van de oplossing
    \item Documentatie van het proces en resultaten
    \item Uitschrijven, aanpassen van het proefschrift
\end{itemize}
\par
De onderstaande tijdsplanning geeft een overzicht van de beoogde deliverables en mijlpalen per sprint.
\begin{itemize}
    \item \textbf{Sprint 1}
        \begin{itemize}
            \item Relevante modellen zijn verzameld en uitgetest binnen een Python Notebook.
            \item Er zijn huisgemaakte data verzameld via geleende Tobii Glasses uit het Zorglab.
            \item Potentiële segmentatie- en detectiepipeline architecturen voor de PoC zijn uitgestippeld.
            \item Er is een user interface binnen de PoC om opnames op te halen van de Tobii Glasses.
        \end{itemize}
    \item \textbf{Sprint 2}
        \begin{itemize}
            \item Er is zorglab-specifieke data\newline aangevraagd.
            \item De abstract en inleiding van het proefschrift zijn geschreven.
            \item Het literatuurstudie onderdeel van het proefschrift is uitgewerkt.
        \end{itemize}
        \item \textbf{Sprint 3}
        \begin{itemize}
            \item Er is een demo gegeven aan de\newline co-promotor voor een kandidaat\newline architectuur van de PoC.
            \item De feedback van de co-promotor is verwerkt en gedocumenteerd.
            \item Er is een metriek ontwikkeld voor het meten van waar een student naar heeft gekeken en voor hoe lang.
            \item Er zijn verschillende data-architecturen geëvalueerd.
        \end{itemize}
    \item \textbf{Sprint 4}
        \begin{itemize}
            \item De segmentatie- en detectiepipeline is geïntegreerd binnen de user interface van de PoC
            \item De vergelijking tussen verschillende\newline data-architecturen is toegevoegd aan\newline het proefschrift.
            \item Er is een meeting gebeurd met de co-promotor voor feedback op de PoC.
        \end{itemize}
    \item \textbf{Sprint 5}
        \begin{itemize}
            \item De objectdetectie- en segmentatiemodellen zijn geïntegreerd binnen de PoC.
            \item Zorglab-specifieke data is gelabeld en gebruikt voor het valideren van de PoC.
        \end{itemize}
    \item \textbf{Sprint 6}
        \begin{itemize}
            \item De visualisatie-interface is ontwikkeld\newline en geïntegreerd binnen de PoC.
            \item De gebruiker kan nieuwe video's analyseren en de resultaten bekijken.
            \item De PoC is gevalideerd in het Zorglab.
        \end{itemize}
    \item \textbf{Sprint 7}
        \begin{itemize}
            \item Het proefschrift is gefinaliseerd en ingediend.
        \end{itemize}
\end{itemize}

%---------- Tools en Technologieën ----------------------------------------------
\subsection{Tools en Technologieën}

\begin{itemize} 
  \item \textbf{Programmeertaal en Frameworks}: Python, PyTorch, TensorFlow voor\\ machine-learning modellering en implementatie. 
  \item \textbf{Programmeerstack van de PoC}: FastAPI\newline voor de backend, HTMX en Jinja2 voor de frontend.
  \item \textbf{Data Verwerking en Visualisatie}: OpenCV voor videoverwerking, Matplotlib voor datavisualisatie. 
  \item \textbf{Ontwikkelomgeving}: Visual Studio Code,\newline Python Notebooks voor experimenten, Git voor versiebeheer. Poetry voor dependency management.
  \item \textbf{GPU}: At-home Nvidia RTX 4090 en eventuele GPUs van HoGent.
  \item \textbf{Eyetracking}: Tobii Eyetracking Glasses, en Tobii Pro Glasses 3 Controller App.
  \item \textbf{Planning}: Trello voor projectmanagement.
\end{itemize}

%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat}%
\label{sec:verwachte_resultaten}

Het verwachte resultaat van dit bachelorproefonderzoek is de ontwikkeling van een functionele PoC 
software die objectherkennings- en segmentatiemodellen integreert met de videodata van de Tobii Eyetracking Glasses.
Deze software zal in staat zijn om nauwkeurig te bepalen welke kritische objecten door studenten zijn waargenomen tijdens simulaties, 
ondersteund door visuele representaties van de oogbewegingen. Verwacht wordt dat modellen na fine-tuning met Zorglab-specifieke data, 
een hoge detectienauwkeurigheid zullen bereiken.
\par
Trainers en lesgevers in het 360° Zorglab, zullen baat hebben bij een efficiëntere en gedetailleerdere 
evaluatie van de observatieprestaties van studenten. De ontwikkelde software biedt een meerwaarde door het mogelijk 
te maken gerichte feedback te geven op specifieke waarnemingen, waardoor het leerproces wordt geoptimaliseerd. 
Bovendien draagt de PoC bij aan de verdere automatisering van het beoordelingsproces, wat leidt tot tijdbesparing. 
Het onderzoek zal ook inzicht bieden in de effectiviteit van verschillende 
machine-learning modellen binnen de context van eyetrackingdata, wat kennis oplevert voor toekomstige toepassingen en verbeteringen in het Zorglab.