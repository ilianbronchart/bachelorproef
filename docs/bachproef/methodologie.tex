%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{\IfLanguageName{dutch}{Methodologie}{Methodology}}%
\label{ch:methodologie}

%% TODO: In dit hoofstuk geef je een korte toelichting over hoe je te werk bent
%% gegaan. Verdeel je onderzoek in grote fasen, en licht in elke fase toe wat
%% de doelstelling was, welke deliverables daar uit gekomen zijn, en welke
%% onderzoeksmethoden je daarbij toegepast hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent.
%% 
%% Voorbeelden van zulke fasen zijn: literatuurstudie, opstellen van een
%% requirements-analyse, opstellen long-list (bij vergelijkende studie),
%% selectie van geschikte tools (bij vergelijkende studie, "short-list"),
%% opzetten testopstelling/PoC, uitvoeren testen en verzamelen
%% van resultaten, analyse van resultaten, ...
%%
%% !!!!! LET OP !!!!!
%%
%% Het is uitdrukkelijk NIET de bedoeling dat je het grootste deel van de corpus
%% van je bachelorproef in dit hoofstuk verwerkt! Dit hoofdstuk is eerder een
%% kort overzicht van je plan van aanpak.
%%
%% Maak voor elke fase (behalve het literatuuronderzoek) een NIEUW HOOFDSTUK aan
%% en geef het een gepaste titel.

Het onderzoek werd uitgevoerd in een iteratieve cyclus, waarbij de verschillende fasen van het project elkaar opvolgden en elkaar beïnvloedden.
Deze sectie beschrijft in grote lijnen de verschillende fasen van het onderzoek, de doelstellingen en de gebruikte methodologieën.

\section{Literatuurstudie}

De literatuurstudie vormde een iteratief proces gedurende het gehele onderzoek, beginnend met een brede initiële verkenning en 
later verfijnd en aangevuld naarmate specifieke vragen tijdens het project opdoken. 
Het overkoepelende doel was een grondig en actueel inzicht te verwerven in de relevante domeinen. 
Hierbij lag de focus op drie kerngebieden: 
\begin{enumerate}
\item De huidige stand van zaken in eyetracking-technologie, met specifieke aandacht voor hoofd-gemonteerde systemen zoals de Tobii Pro Glasses 3 en de analyse van de hieruit voortkomende data (fixaties, saccades, AOI's).
\item State-of-the-art technieken binnen Computer Vision, waaronder objectdetectie (bv. YOLO, DETR, Grounding DINO), segmentatie (bv. Mask R-CNN, SAM, FastSAM) en image embedding (bv. CLIP, DINOv2).
\item Bestaande integraties van eyetracking en Computer Vision.
\end{enumerate}
Wetenschappelijke publicaties, technische documentatie en relevante open-source projecten werden hiervoor systematisch 
geraadpleegd en kritisch geanalyseerd.
Hoofdstuk~\ref{ch:stand-van-zaken} beschrijft uitvoerig de bevindingen van deze literatuurstudie.

\section{Oplossingsverkenning}

Voortbouwend op de inzichten uit de literatuurstudie, richtte de tweede fase zich op het verkennen en evalueren van verschillende 
conceptuele oplossingsstrategieën om de centrale onderzoeksvraag te beantwoorden. 
Het doel was om een reeks potentiële benaderingen te formuleren voor het automatisch analyseren 
van eyetrackingdata in combinatie met computervisiemodellen, en hieruit de meest veelbelovende te 
selecteren voor de ontwikkeling van de Proof-of-Concept (PoC). 
Dit proces omvatte het conceptueel ontwerpen van diverse pipelines, waarbij de inputs (eyetracking-opnames, objectdefinities) 
en de gewenste outputs (geobserveerde objecten, observatieduur) als leidraad dienden. 
De strategieën varieerden in de mate van automatisering, de typen computervisiemodellen 
(bv. vooraf getrainde specifieke modellen, zero-shot modellen, segmentatie-gebaseerde classificatie) 
en de rol van de blikdata in het proces. 
Elke strategie werd kwalitatief beoordeeld op criteria zoals verwachte accuraatheid, complexiteit van implementatie, 
computationele vereisten en flexibiliteit. 
Deze analyse resulteerde in een beargumenteerde keuze voor de strategie die als basis diende voor de PoC, 
zoals gedetailleerd in Hoofdstuk~\ref{ch:oplossingsstrategieen}.

\section{Huisgemaakte Data}

Voor het onderzoek en het uitwerken van de PoC software-applicatie, was het belangrijk om zicht te krijgen op de werking van de Eyetracker en de bijhorende software.
Daarom werd deze ontleend uit het Zorglab van HoGent voor een periode van 3 weken. 
Tijdens deze periode werden thuis verschillende opnames gemaakt in een woonkamer met diverse objecten, met de volgende specifieke doelstellingen:
\begin{itemize}
    \item Het leren werken met de Tobii Pro Glasses 3 en de bijhorende software.
    \item Nagaan hoe men de eyetrackingdata kan exporteren naar een bruikbaar formaat via de WiFi-verbinding van de eyetracker.
    \item Een dataset creëren die kan dienen als basis voor het uitwerken van de PoC.
\end{itemize}
Deze opnames werden niet gebruikt voor de uiteindelijke evaluatie van de PoC, aangezien de data afkomstig zijn van tests waarbij de onderzoeker zelf de eyetracker droeg.
Hierdoor is er sprake van mogelijke bias, wat de objectiviteit van de data in het gedrang brengt.

\section{Proof of Concept Software Applicatie}

Een kernonderdeel van deze bachelorproef was de ontwikkeling van een Proof-of-Concept (PoC) softwareapplicatie. 
Het hoofddoel van deze fase was het ontwerpen en implementeren van een werkend prototype dat de beoogde workflow ondersteunt: van het importeren van ruwe eyetracking-opnames tot het genereren van geannoteerde data die als basis kan dienen voor analyse. 
De methodologie omvatte de selectie van een passende, moderne technologie-stack (o.a. Python, FastAPI, HTMX, SQLite) gericht op modulariteit en toekomstige uitbreidbaarheid. 
Een significant onderdeel was het ontwerp en de implementatie van een semi-automatische labeling-tool, bedoeld om de efficiëntie van het annotatieproces te verhogen. 
Er werd ingezet op goede software-ontwikkelpraktijken zoals type hinting en containerisatie (Docker) om de onderhoudbaarheid en reproduceerbaarheid te waarborgen. 
De resulterende applicatie, inclusief de architectuur, componenten en technische keuzes, wordt uitvoerig beschreven in Hoofdstuk~\ref{ch:ontwikkeling}.

\section{Experimenteel Onderzoek}

Zoals eerder vermeld, werd de thuisopgenomen dataset niet gebruikt voor de evaluatie van de PoC. 
Om een onbevooroordeelde dataset te verkrijgen en om de modaliteiten van de uitwerking te valideren (bijvoorbeeld: invloed van de afstand tussen de Eyetracker en het object, en de aard van de objecten), werd er een gecontroleerd experiment opgezet in het Zorglab van HoGent.
Het doel van dit experiment was om een dataset te creëren die als grond-waarheid diende voor de metrieken die de PoC berekent (bekeken objecten en tijdsduur).
Op de campus werden studenten van diverse opleidingen gevraagd om deel te nemen aan het experiment.
De 14 resulterende opnames werden daarna gelabeld via de labeling-tool van de PoC, met een kwaliteitscontrole om de betrouwbaarheid van de data te waarborgen.
Voor een uitgebreide beschrijving van de opzet en uitvoering van het experiment, inclusief de gebruikte methodologieën, wordt verwezen naar Hoofdstuk~\ref{ch:experiment}.

\section{Creatie van een Grondwaarheidsdataset}

Om de prestaties van de geautomatiseerde analysemethoden objectief te kunnen evalueren, was de creatie van een nauwkeurige 
grondwaarheidsdataset noodzakelijk. Het doel van deze fase was om, voor elke evaluatieopname uit het experiment, 
frame per frame vast te stellen welke van de 15 gedefinieerde objecten daadwerkelijk door de deelnemer werden bekeken. 
De methodologie startte met het voorbereiden van de ruwe opnamedata (video en blikdata). 
Vervolgens werden de evaluatieopnames geannoteerd met behulp van de ontwikkelde labeling-tool (zie Hoofdstuk~\ref{ch:ontwikkeling}), 
waarbij de onderzoeker objecten waar de blik van de deelnemer op rustte, segmenteerde met behulp van het SAM2-model en de trackingfunctionaliteit. 
Deze initiële segmentaties werden daarna gefilterd op basis van de geregistreerde blikpunten, waarbij een cirkelvormig kijkgebied 
(gebaseerd op foveaal zicht en eyetracker-nauwkeurigheid) moest overlappen met het segmentatiemasker. 
Dit resulteerde in een dataset die per frame de bekeken objecten, hun bounding boxes en maskeroppervlakte specificeert. 
De correctheid werd manueel gevalideerd. De gedetailleerde stappen van dit proces zijn beschreven in Hoofdstuk~\ref{ch:grondwaarheid}.

\section{Analyse van Observatieprestaties}
% TODO aanpassen op het einde

De laatste fase van het onderzoek focuste op het implementeren en evalueren van een geautomatiseerde analysepipeline om observatieprestaties te meten, conform de gekozen oplossingsstrategie (Strategie 4 uit Hoofdstuk~\ref{ch:oplossingsstrategieen}). Het doel was om automatisch te bepalen welke kritische objecten werden waargenomen en hoe lang, en dit te vergelijken met de grondwaarheidsdataset. De methodologie omvatte:
\begin{enumerate}
  \item Het toepassen van "everything-segmentation" en tracking met FastSAM op de evaluatieopnames.
  \item Het filteren van de resulterende segmenten op basis van objectgrootte en de geregistreerde 
  blikdata (overlap met het blikpunt), wat resulteerde in de te classificeren object ROIs (Regions of Interest).
  \item Het classificeren van deze ROIs met twee verschillende methoden: de eerste gebaseerd op DINOv2 image 
  embeddings in combinatie met een Faiss vector-index voor similariteitsmatching tegenover voorbeelden uit de kalibratieopnames, 
  en de tweede gebaseerd op een YOLO-classificatiemodel getraind op dezelfde voorbeelden.
\end{enumerate}
De prestaties van beide methoden werden kwantitatief beoordeeld ten opzichte van de grondwaarheid. 
Dit proces en de resultaten worden gedetailleerd in Hoofdstuk~\ref{ch:analyse}.
